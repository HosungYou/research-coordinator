# CLAUDE.md

# Diverga v8.1.0 (Checkpoint Enforcement Strengthening)

**Beyond Modal: AI Research Assistant That Thinks Creatively**

**v8.1.0**: Checkpoint Enforcement Strengthening - Mandatory AskUserQuestion at all checkpoints, Agent Prerequisite Map, multi-agent coordination
**v8.0.1-patch3**: 8-Dimension Diagnostic Sweep - Category I registration fix, version sync, lib/ fixes
**v8.0.1**: Installation Bug Fixes - Fixed install script path corruption, skills copy instead of symlink
**v8.0.0**: Project Visibility Enhancement - Independent HUD, simplified setup, natural language project start, docs/ auto-generation
**v7.0.0**: Memory System - 3-layer context, checkpoint auto-trigger, cross-session persistence
**v6.9.2**: Marketplace Cache Fix - Fixed cache sync issue, comprehensive troubleshooting guide
**v6.9.1**: Plugin Discovery Fix - Added version field to SKILL.md, removed orphaned directories, local symlinks
**v6.8.0**: Memory System - Persistent context preservation with semantic search and lifecycle hooks
**v6.7.0**: Systematic Review Automation - Category I agents (I0-I3) for PRISMA 2020 pipeline
**v6.6.3**: Codex CLI SKILL.md implementation - actual skill loading via `.codex/skills/`
**v6.6.2**: Multi-CLI Compatibility - unified install script, NPM package (@diverga/codex-setup)
**v6.5.0**: Parallel execution via Task tool - `Task(subagent_type="diverga:a1", ...)`
**v6.4**: Plugin Marketplace Registration - Install via `/plugin marketplace add`

## v8.0 Key Features

### 1. File Structure Redesign
- `.research/` = System files (hidden)
- `docs/` = Researcher-visible documentation (auto-generated)

### 2. Independent HUD Statusline
- Completely independent of oh-my-claudecode
- Shows project name, stage, checkpoint progress, memory health
- Multiple presets: research, checkpoint, memory, minimal

### 3. Simplified Setup (2 Steps)
- Removed LLM selection (Claude Code already authenticated)
- Checkpoint level + HUD in single screen
- Auto-project detection

### 4. Natural Language Project Start
- "I want to conduct a systematic review on AI in education" â†’ auto-detect & initialize
- Works in English and Korean

AI Research Assistant for the Complete Research Lifecycle - from question formulation to publication.

**Language**: English. Responds in Korean when user input is Korean.

---

## Installation

### Recommended Method (Local Skills - Most Reliable)

```bash
# Step 1: Clone repository
git clone https://github.com/HosungYou/Diverga.git
cd Diverga

# Step 2: Create local skill symlinks
for skill_dir in skills/*/; do
  skill_name=$(basename "$skill_dir")
  cp -r "$skill_dir" ~/.claude/skills/diverga-${skill_name}
done

# Step 3: Restart Claude Code

# Step 4: Verify
/diverga-help       # Should display help guide
```

### Alternative Method (Plugin Marketplace)

```bash
# Step 1: Add to marketplace
/plugin marketplace add https://github.com/HosungYou/Diverga

# Step 2: Install
/plugin install diverga

# Step 3: Configure
/diverga-setup
```

### Skill Access

| Method | Command | Reliability |
|--------|---------|-------------|
| **Hyphen prefix** | `/diverga-help` | âœ… Always works |
| Colon prefix | `/diverga:help` | âš ï¸ Requires plugin load |

**Recommendation**: Use hyphen prefix (`/diverga-xxx`) for reliable skill invocation.

---

## v6.0 Clean Slate Changes

| Change | v5.0 (Sisyphus) | v6.0 (Human-Centered) |
|--------|-----------------|----------------------|
| **Sisyphus Protocol** | "Work never stops" | âŒ REMOVED |
| **Iron Law** | "agent OR checkpoint" | âŒ REMOVED |
| **ralph/ultrawork/ecomode** | Autonomous modes | âŒ REMOVED |
| **Human Checkpoints** | Could be bypassed | âœ… MANDATORY |
| **Model Routing** | haiku/sonnet/opus | âœ… KEPT |
| **VS Methodology** | Creative alternatives | âœ… ENHANCED |

---

## Project Overview

Diverga provides **context-persistent research support** through **44 specialized agents** across 9 categories (A-I). Unlike other AI tools that suffer from **mode collapse** (always recommending the same predictable options), Diverga uses **Verbalized Sampling (VS) methodology** to guide you toward creative, defensible research choices while maintaining research context across the entire project lifecycle in a single platform.

## Core Value Proposition

1. **Human-Centered**: AI assists, humans decide at EVERY critical point
2. **Beyond Modal**: VS methodology prevents mode collapse - creative alternatives, not obvious choices
3. **Context Persistence**: No re-explaining your research question, methodology, or decisions
4. **Single Platform**: Claude Code as your unified research environment
5. **Research Pipeline**: Structured workflow from idea to publication
6. **Tool Discovery**: Easy access to tools/platforms you didn't know existed

> **Core Principle**: "Human decisions remain with humans. AI handles what's beyond human scope."
> "ì¸ê°„ì´ í•  ì¼ì€ ì¸ê°„ì´, AIëŠ” ì¸ê°„ì˜ ë²”ì£¼ë¥¼ ë²—ì–´ë‚œ ê²ƒì„ ìˆ˜í–‰"

---

## Quick Start

Simply tell Diverga what you want to do:

```
"I want to conduct a systematic review on AI in education"
"ë©”íƒ€ë¶„ì„ ì—°êµ¬ë¥¼ ì‹œìž‘í•˜ê³  ì‹¶ì–´"
"Help me design an experimental study"
```

The system will:
1. Detect your paradigm
2. **ASK for confirmation** (ðŸ”´ CHECKPOINT)
3. Present VS alternatives with T-Scores
4. **WAIT for your selection**
5. Guide you through the pipeline with checkpoints

---

## Memory System (v7.0 Core Feature)

### Overview

Diverga Memory System provides **context-persistent research support** with:
- **3-Layer Context System**: Keyword-triggered, Task interceptor, CLI-based loading
- **Checkpoint Auto-Trigger**: Automatic enforcement at critical decision points
- **Cross-Session Persistence**: Decisions and progress survive session restarts
- **Decision Audit Trail**: Immutable, versioned history of all research decisions

### 3-Layer Context System

| Layer | Trigger | Description |
|-------|---------|-------------|
| **Layer 1** | Keywords | "my research", "ì—°êµ¬ ì§„í–‰", "where was I" auto-load context |
| **Layer 2** | Task tool | `Task(subagent_type="diverga:*")` auto-injects context to agents |
| **Layer 3** | CLI | `/diverga:memory context` for explicit full context |

### Memory Commands

| Command | Description |
|---------|-------------|
| `/diverga:memory status` | Show project status |
| `/diverga:memory context` | Display full context |
| `/diverga:memory init` | Initialize new project |
| `/diverga:memory decision list` | List decisions |
| `/diverga:memory decision add` | Add decision |
| `/diverga:memory archive [STAGE]` | Archive completed stage |
| `/diverga:memory migrate` | Run v6.8 â†’ v7.0 migration |

### Project Structure

```
.research/
â”œâ”€â”€ baselines/           # Stable research foundations
â”‚   â”œâ”€â”€ literature/
â”‚   â”œâ”€â”€ methodology/
â”‚   â””â”€â”€ framework/
â”œâ”€â”€ changes/
â”‚   â”œâ”€â”€ current/         # Active work
â”‚   â””â”€â”€ archive/         # Completed stages
â”œâ”€â”€ sessions/            # Session records
â”œâ”€â”€ project-state.yaml   # Project metadata
â”œâ”€â”€ decision-log.yaml    # All decisions
â””â”€â”€ checkpoints.yaml     # Checkpoint states
```

### Context Keywords (English + Korean)

**English**: "my research", "research status", "research progress", "where was I", "continue research"

**Korean**: "ë‚´ ì—°êµ¬", "ì—°êµ¬ ì§„í–‰", "ì—°êµ¬ ìƒíƒœ", "ì–´ë””ê¹Œì§€", "ì§€ê¸ˆ ë‹¨ê³„"

---

## Human Checkpoint System (v6.0 Core Feature)

### Checkpoint Types

| Level | Icon | Behavior |
|-------|------|----------|
| **REQUIRED** | ðŸ”´ | System STOPS - Cannot proceed without explicit approval |
| **RECOMMENDED** | ðŸŸ  | System PAUSES - Strongly suggests approval |
| **OPTIONAL** | ðŸŸ¡ | System ASKS - Defaults available if skipped |

### Required Checkpoints (ðŸ”´ MANDATORY)

| Checkpoint | When | What Happens |
|------------|------|--------------|
| CP_RESEARCH_DIRECTION | Research question finalized | Present VS options, WAIT for selection |
| CP_PARADIGM_SELECTION | Methodology approach | Ask Quantitative/Qualitative/Mixed |
| CP_THEORY_SELECTION | Framework chosen | Present alternatives with T-Scores |
| CP_METHODOLOGY_APPROVAL | Design complete | Detailed review required |

### Checkpoint Behavior

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CHECKPOINT PROTOCOL                          â”‚
â”‚                                                                â”‚
â”‚   When AI reaches a checkpoint:                                â”‚
â”‚                                                                â”‚
â”‚   1. STOP immediately                                          â”‚
â”‚   2. Present options with VS alternatives                      â”‚
â”‚   3. WAIT for explicit human approval                          â”‚
â”‚   4. DO NOT proceed until approval received                    â”‚
â”‚   5. DO NOT assume approval based on context                   â”‚
â”‚                                                                â”‚
â”‚   [X] NEVER: "Proceeding with..." without asking              â”‚
â”‚   [OK] ALWAYS: "Which direction would you like to proceed?"   â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Checkpoint Enforcement Protocol (MANDATORY)

### Rule 1: AskUserQuestion ë„êµ¬ ì‚¬ìš© ì˜ë¬´
ì²´í¬í¬ì¸íŠ¸ ë„ë‹¬ ì‹œ ë°˜ë“œì‹œ `AskUserQuestion` ë„êµ¬ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
í…ìŠ¤íŠ¸ë¡œ ë¬»ëŠ” ê²ƒì€ ì²´í¬í¬ì¸íŠ¸ ì¶©ì¡±ìœ¼ë¡œ ì¸ì •ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

âŒ ê¸ˆì§€: "ì–´ë–»ê²Œ í•˜ì‹œê² ìŠµë‹ˆê¹Œ?" (í…ìŠ¤íŠ¸ ì§ˆë¬¸)
âœ… í•„ìˆ˜: AskUserQuestion ë„êµ¬ í˜¸ì¶œ (êµ¬ì¡°í™”ëœ ì„ íƒì§€)

### Rule 2: ì „ì œì¡°ê±´ Gate (ìŠ¤í‚µ ë¶ˆê°€)
ì—ì´ì „íŠ¸ í˜¸ì¶œ ì‹œ, í•´ë‹¹ ì—ì´ì „íŠ¸ì˜ prerequisite ì²´í¬í¬ì¸íŠ¸ê°€
ì´ì „ì— ì‚¬ìš©ìžì˜ ëª…ì‹œì  ìŠ¹ì¸ì„ ë°›ì•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
ìŠ¹ì¸ ì´ë ¥ì´ ì—†ìœ¼ë©´ í•´ë‹¹ ì²´í¬í¬ì¸íŠ¸ë¶€í„° ìˆœì„œëŒ€ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.
REQUIRED ì²´í¬í¬ì¸íŠ¸ëŠ” ì‚¬ìš©ìž ìš”ì²­ìœ¼ë¡œë„ ê±´ë„ˆë›¸ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

### Rule 3: Ad-hoc í˜¸ì¶œ ì²˜ë¦¬
ì—ì´ì „íŠ¸ë¥¼ ì§ì ‘ í˜¸ì¶œí–ˆì„ ë•Œ (ì˜ˆ: /diverga:c5):
1. Agent Prerequisite Mapì—ì„œ ì „ì œì¡°ê±´ í™•ì¸
2. ë¯¸ì™„ë£Œ ì „ì œì¡°ê±´ì´ ìžˆìœ¼ë©´ AskUserQuestionìœ¼ë¡œ í•´ë‹¹ ê²°ì • ìš”ì²­
3. ëª¨ë“  ì „ì œì¡°ê±´ í†µê³¼ í›„ ì—ì´ì „íŠ¸ ë³¸ì—°ì˜ ìž‘ì—… ì‹œìž‘

### Rule 4: ë™ì‹œ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í˜¸ì¶œ ì²˜ë¦¬
ìžì—°ì–´ë¡œ ë‹¤ìˆ˜ ì—ì´ì „íŠ¸ê°€ ë™ì‹œ íŠ¸ë¦¬ê±°ë  ë•Œ:
1. ëª¨ë“  íŠ¸ë¦¬ê±°ëœ ì—ì´ì „íŠ¸ì˜ ì „ì œì¡°ê±´ì„ í•©ì§‘í•©(Union)ìœ¼ë¡œ ìˆ˜ì§‘
2. ì¤‘ë³µ ì œê±° í›„ ì˜ì¡´ì„± ìˆœì„œ(dependency order)ë¡œ ì •ë ¬
3. ê° ì „ì œì¡°ê±´ì„ ìˆœì„œëŒ€ë¡œ AskUserQuestionìœ¼ë¡œ ì§ˆë¬¸ (í•œ ë²ˆì— ìµœëŒ€ 4ê°œ)
4. ëª¨ë“  ì „ì œì¡°ê±´ í†µê³¼ í›„ ì—ì´ì „íŠ¸ë“¤ì„ ë³‘ë ¬ ì‹¤í–‰
5. ê° ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ìžì²´ ì²´í¬í¬ì¸íŠ¸ë„ ë°˜ë“œì‹œ AskUserQuestion í˜¸ì¶œ

ì˜ˆì‹œ: "ë©”íƒ€ë¶„ì„ ì„¤ê³„í•˜ê³  íš¨ê³¼í¬ê¸° ì¶”ì¶œë„ ê°™ì´" â†’ C5 + B3 íŠ¸ë¦¬ê±°
  â†’ Union prerequisites: {CP_RESEARCH_DIRECTION, CP_METHODOLOGY_APPROVAL}
  â†’ AskUserQuestion: CP_RESEARCH_DIRECTION ë¨¼ì €
  â†’ AskUserQuestion: CP_METHODOLOGY_APPROVAL ë‹¤ìŒ
  â†’ ëª¨ë“  í†µê³¼ í›„ C5 + B3 ë³‘ë ¬ ì‹¤í–‰

### Why Prompt-Level Enforcement
Claude Code shell hooks cannot invoke AskUserQuestion tool directly (shell commands only).
Therefore, CLAUDE.md and SKILL.md prompt-level instructions are the primary enforcement mechanism.

### Agent Prerequisite Map

| Agent | Prerequisites (ë°˜ë“œì‹œ ì™„ë£Œ) | Own Checkpoints (ì‹¤í–‰ ì¤‘ íŠ¸ë¦¬ê±°) |
|-------|---------------------------|-------------------------------|
| A1 | (ì§„ìž…ì ) | ðŸ”´ CP_RESEARCH_DIRECTION, ðŸ”´ CP_VS_001, ðŸ”´ CP_VS_003 |
| A2 | CP_RESEARCH_DIRECTION | ðŸ”´ CP_THEORY_SELECTION, ðŸ”´ CP_VS_001, ðŸŸ  CP_VS_002, ðŸ”´ CP_VS_003 |
| A3 | CP_RESEARCH_DIRECTION | ðŸ”´ CP_VS_001, ðŸ”´ CP_VS_003 |
| A4 | (ì—†ìŒ) | (ì—†ìŒ) |
| A5 | (ì§„ìž…ì ) | ðŸ”´ CP_PARADIGM_SELECTION |
| A6 | CP_RESEARCH_DIRECTION | ðŸŸ¡ CP_VISUALIZATION_PREFERENCE |
| B1 | CP_RESEARCH_DIRECTION | ðŸŸ  CP_SCREENING_CRITERIA, ðŸŸ¡ CP_SEARCH_STRATEGY, ðŸ”´ CP_VS_001 |
| B2 | CP_RESEARCH_DIRECTION | ðŸŸ  CP_QUALITY_REVIEW |
| B3 | (ì—†ìŒ) | (ì—†ìŒ) |
| B4 | (ì—†ìŒ) | (ì—†ìŒ) |
| B5 | (ì—†ìŒ) | (ì—†ìŒ) |
| C1 | CP_PARADIGM_SELECTION, CP_RESEARCH_DIRECTION | ðŸ”´ CP_METHODOLOGY_APPROVAL, ðŸ”´ CP_VS_001, ðŸ”´ CP_VS_003 |
| C2 | CP_PARADIGM_SELECTION, CP_RESEARCH_DIRECTION | ðŸ”´ CP_METHODOLOGY_APPROVAL, ðŸ”´ CP_VS_001 |
| C3 | CP_PARADIGM_SELECTION, CP_RESEARCH_DIRECTION | ðŸ”´ CP_METHODOLOGY_APPROVAL, ðŸŸ  CP_INTEGRATION_STRATEGY |
| C5 | CP_RESEARCH_DIRECTION, CP_METHODOLOGY_APPROVAL | ðŸŸ  CP_ANALYSIS_PLAN |
| C6 | CP_METHODOLOGY_APPROVAL | (ì—†ìŒ) |
| C7 | CP_METHODOLOGY_APPROVAL | (ì—†ìŒ) |
| D1 | CP_METHODOLOGY_APPROVAL | ðŸŸ  CP_SAMPLING_STRATEGY |
| D2 | CP_METHODOLOGY_APPROVAL | ðŸŸ  CP_SAMPLING_STRATEGY |
| D4 | CP_METHODOLOGY_APPROVAL | ðŸ”´ CP_METHODOLOGY_APPROVAL |
| E1 | CP_METHODOLOGY_APPROVAL | ðŸŸ  CP_ANALYSIS_PLAN |
| E2 | CP_METHODOLOGY_APPROVAL | ðŸŸ  CP_CODING_APPROACH, ðŸŸ  CP_THEME_VALIDATION |
| E3 | CP_METHODOLOGY_APPROVAL | ðŸŸ  CP_INTEGRATION_STRATEGY |
| E5 | CP_METHODOLOGY_APPROVAL | (ì—†ìŒ) |
| G3 | (ì—†ìŒ) | (ì—†ìŒ) |
| G5 | (ì—†ìŒ) | ðŸŸ  CP_HUMANIZATION_REVIEW |
| G6 | CP_HUMANIZATION_REVIEW | ðŸŸ¡ CP_HUMANIZATION_VERIFY |
| H1 | CP_PARADIGM_SELECTION | ðŸ”´ CP_METHODOLOGY_APPROVAL |
| H2 | CP_PARADIGM_SELECTION | ðŸ”´ CP_METHODOLOGY_APPROVAL |
| I0 | (ì—†ìŒ) | All SCH_* |
| I1 | (ì—†ìŒ) | ðŸ”´ SCH_DATABASE_SELECTION |
| I2 | SCH_DATABASE_SELECTION | ðŸ”´ SCH_SCREENING_CRITERIA |
| I3 | SCH_SCREENING_CRITERIA | ðŸŸ  SCH_RAG_READINESS |

### Checkpoint Dependency Order

ì „ì œì¡°ê±´ í•´ê²° ìˆœì„œ (ë‚®ì€ Levelë¶€í„°):

```
Level 0 (ì§„ìž…ì ): CP_RESEARCH_DIRECTION, CP_PARADIGM_SELECTION
Level 1: CP_THEORY_SELECTION, CP_METHODOLOGY_APPROVAL
Level 2: CP_ANALYSIS_PLAN, CP_SCREENING_CRITERIA, CP_SAMPLING_STRATEGY, CP_CODING_APPROACH, CP_THEME_VALIDATION, CP_INTEGRATION_STRATEGY, CP_QUALITY_REVIEW
Level 3: SCH_DATABASE_SELECTION, CP_HUMANIZATION_REVIEW, CP_VS_001, CP_VS_002, CP_VS_003
Level 4: SCH_SCREENING_CRITERIA, CP_HUMANIZATION_VERIFY
Level 5: SCH_RAG_READINESS
```

---

## Core Systems

| System | Purpose | Location |
|--------|---------|----------|
| Project State | Context persistence | `.research/project-state.yaml` |
| Decision Log | Human decisions | `.research/decision-log.yaml` |
| Research Coordinator | Main skill definition | `.claude/skills/research-coordinator/SKILL.md` |
| Orchestrator | Agent management | `.claude/skills/research-orchestrator/SKILL.md` |

---

## Agent Structure (44 Agents in 9 Categories)

| Category | Count | Agents | Paradigm |
|----------|-------|--------|----------|
| **A: Foundation** | 6 | A1-ResearchQuestionRefiner, A2-TheoreticalFrameworkArchitect, A3-DevilsAdvocate, A4-ResearchEthicsAdvisor, A5-ParadigmWorldviewAdvisor, **A6-ConceptualFrameworkVisualizer** | All |
| **B: Evidence** | 5 | B1-SystematicLiteratureScout, B2-EvidenceQualityAppraiser, B3-EffectSizeExtractor, B4-ResearchRadar, **B5-ParallelDocumentProcessor** | All |
| **C: Design & Meta-Analysis** | 7 | C1-QuantitativeDesignConsultant, C2-QualitativeDesignConsultant, C3-MixedMethodsDesignConsultant, C4-ExperimentalMaterialsDeveloper, **C5-MetaAnalysisMaster**, **C6-DataIntegrityGuard**, **C7-ErrorPreventionEngine** | Paradigm-specific + Meta-analysis |
| **D: Data Collection** | 4 | D1-SamplingStrategyAdvisor, D2-InterviewFocusGroupSpecialist, D3-ObservationProtocolDesigner, D4-MeasurementInstrumentDeveloper | Method-specific |
| **E: Analysis** | 5 | E1-QuantitativeAnalysisGuide, E2-QualitativeCodingSpecialist, E3-MixedMethodsIntegration, E4-AnalysisCodeGenerator, **E5-SensitivityAnalysisDesigner** | Paradigm-specific |
| **F: Quality** | 5 | F1-InternalConsistencyChecker, F2-ChecklistManager, F3-ReproducibilityAuditor, F4-BiasTrustworthinessDetector, **F5-HumanizationVerifier** | All |
| **G: Communication** | 6 | G1-JournalMatcher, G2-AcademicCommunicator, G3-PeerReviewStrategist, G4-PreregistrationComposer, **G5-AcademicStyleAuditor**, **G6-AcademicStyleHumanizer** | All |
| **H: Specialized** | 2 | H1-EthnographicResearchAdvisor, H2-ActionResearchFacilitator | Qual |
| **I: Systematic Review Automation** | 4 | **I0-ReviewPipelineOrchestrator**, **I1-PaperRetrievalAgent**, **I2-ScreeningAssistant**, **I3-RAGBuilder** | All |

**Total: 6 + 5 + 7 + 4 + 5 + 5 + 6 + 2 + 4 = 44 agents**

### New in v6.3: Meta-Analysis Agent System (C5/C6/C7)

Based on V7 GenAI meta-analysis lessons learned:

| Agent | Purpose | Model |
|-------|---------|-------|
| **C5-MetaAnalysisMaster** | Multi-gate validation, workflow orchestration | Opus |
| **C6-DataIntegrityGuard** | Data completeness, Hedges' g calculation, SD recovery | Sonnet |
| **C7-ErrorPreventionEngine** | Pattern detection, anomaly alerts, error prevention | Sonnet |

**Authority Model**:
- C5 = Decision Authority (gate pass/fail)
- C6 = Service Provider (data integrity reports)
- C7 = Advisory (warnings, recommendations)

### New in v6.1: Humanization Pipeline Agents

| Agent | Purpose | Model |
|-------|---------|-------|
| **G5-AcademicStyleAuditor** | AI pattern detection (24 categories) | Sonnet |
| **G6-AcademicStyleHumanizer** | Transform AI patterns to natural prose | Opus |
| **F5-HumanizationVerifier** | Verify transformation integrity | Haiku |

### New in v6.2: Parallel Document Processing

| Agent | Purpose | Model |
|-------|---------|-------|
| **B5-ParallelDocumentProcessor** | Batch PDF processing with parallel workers | Opus |

### New in v6.7.0: Systematic Review Automation (Category I)

PRISMA 2020 compliant systematic literature review pipeline with automated paper retrieval, screening, and RAG building.

| Agent | Purpose | Model | Checkpoint |
|-------|---------|-------|------------|
| **I0-ReviewPipelineOrchestrator** | Pipeline coordination, stage management | Opus | - |
| **I1-PaperRetrievalAgent** | Multi-database fetching (Semantic Scholar, OpenAlex, arXiv) | Sonnet | ðŸ”´ SCH_DATABASE_SELECTION |
| **I2-ScreeningAssistant** | AI-PRISMA 6-dimension screening | Sonnet | ðŸ”´ SCH_SCREENING_CRITERIA |
| **I3-RAGBuilder** | Vector database construction (zero cost) | Haiku | ðŸŸ  SCH_RAG_READINESS |

**Human Checkpoints**:
- ðŸ”´ **SCH_DATABASE_SELECTION**: User must approve database selection before retrieval
- ðŸ”´ **SCH_SCREENING_CRITERIA**: User must approve inclusion/exclusion criteria
- ðŸŸ  **SCH_RAG_READINESS**: Recommended checkpoint before RAG queries
- ðŸŸ¡ **SCH_PRISMA_GENERATION**: Optional checkpoint before PRISMA flow diagram generation

---

## Model Routing (v8.0)

| Tier | Model | Agents (44 total) |
|------|-------|-------------------|
| HIGH | Opus | A1, A2, A3, A5, **B5**, C1, C2, C3, D4, E1, E2, E3, G3, **G6**, H1, H2, **I0** (17) |
| MEDIUM | Sonnet | A4, A6, B1, B2, C4, D1, D2, E5, F3, F4, G1, G2, G4, **G5**, **I1**, **I2** (16) |
| LOW | Haiku | B3, B4, D3, E4, F1, F2, **F5**, **I3** (8) |

---

## Research Types Supported

**Quantitative:**
- Experimental designs (RCT, quasi-experimental)
- Survey research
- Meta-analysis and systematic reviews
- Correlational studies
- Psychometric validation

**Qualitative:**
- Phenomenology
- Grounded theory
- Case study
- Ethnography
- Narrative inquiry
- Action research

**Mixed Methods:**
- Sequential (explanatory, exploratory)
- Convergent parallel
- Embedded design
- Transformative frameworks

---

## VS Methodology (Enhanced in v6.0)

### T-Score (Typicality Score)

| T-Score | Label | Meaning |
|---------|-------|---------|
| >= 0.7 | Common | Highly typical, safe but limited novelty |
| 0.4-0.7 | Moderate | Balanced risk-novelty |
| 0.2-0.4 | Innovative | Novel, requires strong justification |
| < 0.2 | Experimental | Highly novel, high risk/reward |

### VS Process with Human Decision

```
Stage 1: Context & Modal Identification
  â””â”€ Identify "obvious" recommendations

Stage 2: Divergent Exploration
  â”œâ”€ Direction A (T~0.6): Safe but differentiated
  â”œâ”€ Direction B (T~0.4): Balanced novelty â­
  â””â”€ Direction C (T<0.3): Innovative/experimental

Stage 3: Human Selection (ðŸ”´ CHECKPOINT)
  â”œâ”€ Present ALL options with T-Scores
  â”œâ”€ WAIT for human decision
  â””â”€ Execute ONLY selected direction
```

---

## Tool Integrations

### Ready to Use (No Setup)
- **Excel**: Data extraction, coding â†’ "Create extraction spreadsheet"
- **PowerPoint**: Presentations â†’ "Create conference slides"
- **Word**: Manuscripts â†’ "Export methods to Word"
- **Python**: Analysis â†’ Built-in
- **Mermaid**: Diagrams â†’ "Create PRISMA flow diagram"

### Needs Setup
- **Semantic Scholar**: API key for literature search
- **OpenAlex**: Email for polite pool
- **Zotero**: MCP server for references
- **R Scripts**: Local R installation
- **Nanobanana**: Gemini API key for visualization

---

## Paradigm Detection (Auto-Activation + Confirmation)

### Auto-Detection Triggers

**Quantitative signals:** "hypothesis", "effect size", "p-value", "experiment", "ANOVA", "regression", "ê°€ì„¤", "íš¨ê³¼í¬ê¸°", "í†µê³„"

**Qualitative signals:** "lived experience", "saturation", "themes", "phenomenology", "coding", "ì²´í—˜", "í¬í™”", "í˜„ìƒí•™"

**Mixed methods signals:** "sequential", "convergent", "integration", "joint display", "í˜¼í•©ë°©ë²•", "í†µí•©"

### Confirmation (Always Ask)

When paradigm is detected, **ALWAYS ask for confirmation**:

```
"A [Quantitative] research approach has been detected from your context.
Shall we proceed with this paradigm?

 [Q] Yes, proceed with Quantitative research
 [L] No, switch to Qualitative research
 [M] No, switch to Mixed Methods
 [?] I'm not sure, I need help"
```

---

## Humanization Pipeline (v6.1 New Feature)

### Overview

Transform AI-generated academic text into natural, human-sounding prose while preserving scholarly integrity. Based on Wikipedia's AI Cleanup initiative's 24 pattern categories, adapted for academic writing.

### Pipeline Stages

```
Content Generation (G2/G3) â†’ G5 Analysis â†’ Checkpoint â†’ G6 Transform â†’ F5 Verify â†’ Export
```

### Commands

| Command | Description |
|---------|-------------|
| `"Check AI patterns"` | Run G5 analysis, show pattern report |
| `"Humanize my draft"` | Full pipeline with balanced mode |
| `"Humanize (conservative)"` | Minimal changes, high-risk only |
| `"Humanize (aggressive)"` | Maximum naturalness |
| `"Export with humanization"` | Run pipeline before export |

### Transformation Modes

| Mode | Target | Best For |
|------|--------|----------|
| **Conservative** | High-risk patterns only | Journal submissions |
| **Balanced** â­ | High + medium-risk | Most academic writing |
| **Aggressive** | All patterns | Blog posts, informal |

### New Checkpoint

| Checkpoint | Level | When |
|------------|-------|------|
| CP_HUMANIZATION_REVIEW | ðŸŸ  Recommended | After content generation |
| CP_HUMANIZATION_VERIFY | ðŸŸ¡ Optional | Before final export |

### Ethics Note

Humanization helps express ideas naturallyâ€”it does NOT make AI use "undetectable."
Researchers should follow institutional and journal AI disclosure policies.

See: `.claude/skills/research-coordinator/ethics/ai-writing-ethics.md`

---

## What Was Removed in v6.0

### âŒ Sisyphus Protocol
- **Was**: "Work never stops until complete"
- **Problem**: Bypassed human checkpoints
- **Now**: AI stops at every checkpoint and waits

### âŒ Iron Law of Continuation
- **Was**: "Move to next agent OR human checkpoint"
- **Problem**: "OR" made checkpoints optional
- **Now**: Checkpoint THEN next agent (sequential)

### âŒ OMC Autonomous Modes
- **Removed**: ralph, ultrawork, autopilot, ecomode
- **Problem**: These modes enabled checkpoint bypass
- **Kept**: Model routing (haiku/sonnet/opus) only

---

## GitHub Repository

https://github.com/HosungYou/Diverga

---

## Auto-Trigger Agent Dispatch (v6.4 Core Feature)

Diverga automatically detects keywords and context to activate appropriate agents via Task tool.

### Agent Invocation Pattern

When Claude Code detects trigger keywords, it automatically invokes agents:

```python
Task(
    subagent_type="diverga:<agent_id>",
    model="<opus|sonnet|haiku>",
    prompt="<research context + specific task>"
)
```

### Complete Auto-Trigger Reference

#### Category A: Foundation (6 agents)

| Agent | Trigger Keywords (EN) | íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ (KR) | Model |
|-------|----------------------|-------------------|-------|
| `diverga:a1` | "research question", "RQ", "refine question" | "ì—°êµ¬ ì§ˆë¬¸", "ì—°êµ¬ë¬¸ì œ", "RQ" | opus |
| `diverga:a2` | "theoretical framework", "theory", "conceptual model" | "ì´ë¡ ì  í”„ë ˆìž„ì›Œí¬", "ì´ë¡ ì  í‹€" | opus |
| `diverga:a3` | "devil's advocate", "critique", "counterargument" | "ë°˜ë¡ ", "ë¹„íŒì  ê²€í† ", "ë°˜ëŒ€ ì˜ê²¬" | opus |
| `diverga:a4` | "IRB", "ethics", "informed consent", "research ethics" | "ì—°êµ¬ ìœ¤ë¦¬", "IRB", "ë™ì˜ì„œ" | sonnet |
| `diverga:a5` | "paradigm", "ontology", "epistemology", "worldview" | "íŒ¨ëŸ¬ë‹¤ìž„", "ì¡´ìž¬ë¡ ", "ì¸ì‹ë¡ " | opus |
| `diverga:a6` | "conceptual framework", "visualize framework" | "ê°œë…ì  í”„ë ˆìž„ì›Œí¬", "í”„ë ˆìž„ì›Œí¬ ì‹œê°í™”" | sonnet |

#### Category B: Evidence (5 agents)

| Agent | Trigger Keywords (EN) | íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ (KR) | Model |
|-------|----------------------|-------------------|-------|
| `diverga:b1` | "systematic review", "literature search", "PRISMA" | "ì²´ê³„ì  ë¬¸í—Œê³ ì°°", "ë¬¸í—Œ ê²€ìƒ‰" | sonnet |
| `diverga:b2` | "quality appraisal", "RoB", "GRADE", "bias assessment" | "í’ˆì§ˆ í‰ê°€", "ë¹„ëš¤ë¦¼ í‰ê°€" | sonnet |
| `diverga:b3` | "effect size", "extract effect", "Cohen's d", "Hedges' g" | "íš¨ê³¼í¬ê¸°", "íš¨ê³¼ í¬ê¸° ì¶”ì¶œ" | haiku |
| `diverga:b4` | "research trends", "emerging topics", "research radar" | "ì—°êµ¬ ë™í–¥", "íŠ¸ë Œë“œ" | haiku |
| `diverga:b5` | "batch PDF", "parallel processing", "multiple PDFs" | "PDF ì¼ê´„ ì²˜ë¦¬", "ë³‘ë ¬ ì²˜ë¦¬" | opus |

#### Category C: Design & Meta-Analysis (7 agents)

| Agent | Trigger Keywords (EN) | íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ (KR) | Model |
|-------|----------------------|-------------------|-------|
| `diverga:c1` | "quantitative design", "experimental design", "RCT" | "ì–‘ì  ì—°êµ¬ ì„¤ê³„", "ì‹¤í—˜ ì„¤ê³„" | opus |
| `diverga:c2` | "qualitative design", "phenomenology", "grounded theory" | "ì§ˆì  ì—°êµ¬ ì„¤ê³„", "í˜„ìƒí•™", "ê·¼ê±°ì´ë¡ " | opus |
| `diverga:c3` | "mixed methods", "sequential design", "convergent" | "í˜¼í•©ë°©ë²•", "í˜¼í•© ì—°êµ¬", "í†µí•© ì„¤ê³„" | opus |
| `diverga:c4` | "intervention materials", "experimental materials" | "ì¤‘ìž¬ ìžë£Œ", "ì‹¤í—˜ ìžë£Œ ê°œë°œ" | sonnet |
| `diverga:c5` | "meta-analysis", "pooled effect", "heterogeneity" | "ë©”íƒ€ë¶„ì„", "ë©”íƒ€ ë¶„ì„", "í†µí•© íš¨ê³¼" | opus |
| `diverga:c6` | "data extraction", "PDF extract", "extract data" | "ë°ì´í„° ì¶”ì¶œ", "PDF ì¶”ì¶œ", "ìžë£Œ ì¶”ì¶œ" | sonnet |
| `diverga:c7` | "error prevention", "validation", "data check" | "ì˜¤ë¥˜ ë°©ì§€", "ê²€ì¦", "ë°ì´í„° í™•ì¸" | sonnet |

#### Category D: Data Collection (4 agents)

| Agent | Trigger Keywords (EN) | íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ (KR) | Model |
|-------|----------------------|-------------------|-------|
| `diverga:d1` | "sampling", "sample size", "G*Power" | "í‘œì§‘", "í‘œë³¸ í¬ê¸°", "ìƒ˜í”Œë§" | sonnet |
| `diverga:d2` | "interview", "focus group", "interview protocol" | "ì¸í„°ë·°", "ë©´ë‹´", "í¬ì»¤ìŠ¤ ê·¸ë£¹" | sonnet |
| `diverga:d3` | "observation", "observation protocol" | "ê´€ì°°", "ê´€ì°° í”„ë¡œí† ì½œ" | haiku |
| `diverga:d4` | "instrument", "measurement", "scale development" | "ì¸¡ì • ë„êµ¬", "ì²™ë„ ê°œë°œ" | opus |

#### Category E: Analysis (5 agents)

| Agent | Trigger Keywords (EN) | íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ (KR) | Model |
|-------|----------------------|-------------------|-------|
| `diverga:e1` | "statistical analysis", "ANOVA", "regression", "SEM" | "í†µê³„ ë¶„ì„", "íšŒê·€", "ë¶„ì‚°ë¶„ì„" | opus |
| `diverga:e2` | "qualitative coding", "thematic analysis", "coding" | "ì§ˆì  ì½”ë”©", "ì£¼ì œ ë¶„ì„", "ì½”ë”©" | opus |
| `diverga:e3` | "mixed methods integration", "joint display" | "í˜¼í•©ë°©ë²• í†µí•©", "í†µí•© ë¶„ì„" | opus |
| `diverga:e4` | "R code", "Python code", "analysis code" | "R ì½”ë“œ", "Python ì½”ë“œ", "ë¶„ì„ ì½”ë“œ" | haiku |
| `diverga:e5` | "sensitivity analysis", "robustness check" | "ë¯¼ê°ë„ ë¶„ì„", "ê°•ê±´ì„± ê²€ì¦" | sonnet |

#### Category F: Quality (5 agents)

| Agent | Trigger Keywords (EN) | íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ (KR) | Model |
|-------|----------------------|-------------------|-------|
| `diverga:f1` | "consistency check", "internal consistency" | "ì¼ê´€ì„± ê²€í† ", "ë‚´ì  ì¼ê´€ì„±" | haiku |
| `diverga:f2` | "checklist", "CONSORT", "STROBE", "COREQ" | "ì²´í¬ë¦¬ìŠ¤íŠ¸", "ë³´ê³  ì§€ì¹¨" | haiku |
| `diverga:f3` | "reproducibility", "replication", "OSF" | "ìž¬í˜„ì„±", "ë°˜ë³µê°€ëŠ¥ì„±" | sonnet |
| `diverga:f4` | "bias detection", "trustworthiness" | "íŽ¸í–¥ íƒì§€", "ì‹ ë¢°ì„±" | sonnet |
| `diverga:f5` | "humanization verify", "AI text check" | "íœ´ë¨¼í™” ê²€ì¦", "AI í…ìŠ¤íŠ¸ í™•ì¸" | haiku |

#### Category G: Communication (6 agents)

| Agent | Trigger Keywords (EN) | íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ (KR) | Model |
|-------|----------------------|-------------------|-------|
| `diverga:g1` | "journal match", "where to publish", "target journal" | "ì €ë„ ë§¤ì¹­", "íˆ¬ê³ ì²˜", "í•™ìˆ ì§€" | sonnet |
| `diverga:g2` | "academic writing", "manuscript", "write paper" | "í•™ìˆ  ê¸€ì“°ê¸°", "ë…¼ë¬¸ ìž‘ì„±" | sonnet |
| `diverga:g3` | "peer review", "reviewer response", "revision" | "ë™ë£Œ ì‹¬ì‚¬", "ë¦¬ë·°ì–´ ì‘ë‹µ", "ìˆ˜ì •" | sonnet |
| `diverga:g4` | "preregistration", "OSF", "pre-register" | "ì‚¬ì „ë“±ë¡", "OSF" | sonnet |
| `diverga:g5` | "AI pattern", "check AI writing", "style audit" | "AI íŒ¨í„´", "AI ê¸€ì“°ê¸° ê²€í† " | sonnet |
| `diverga:g6` | "humanize", "humanization", "natural writing" | "íœ´ë¨¼í™”", "ìžì—°ìŠ¤ëŸ¬ìš´ ê¸€ì“°ê¸°" | opus |

#### Category H: Specialized (2 agents)

| Agent | Trigger Keywords (EN) | íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ (KR) | Model |
|-------|----------------------|-------------------|-------|
| `diverga:h1` | "ethnography", "fieldwork", "participant observation" | "ë¯¼ì¡±ì§€í•™", "í˜„ìž¥ì—°êµ¬", "ì°¸ì—¬ê´€ì°°" | opus |
| `diverga:h2` | "action research", "participatory", "practitioner" | "ì‹¤í–‰ì—°êµ¬", "ì°¸ì—¬ì  ì—°êµ¬" | opus |

#### Category I: Systematic Review Automation (4 agents)

| Agent | Trigger Keywords (EN) | íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ (KR) | Model |
|-------|----------------------|-------------------|-------|
| `diverga:i0` | "systematic review", "PRISMA", "literature review automation" | "ì²´ê³„ì  ë¬¸í—Œê³ ì°°", "í”„ë¦¬ì¦ˆë§ˆ", "ë¬¸í—Œê³ ì°° ìžë™í™”" | opus |
| `diverga:i1` | "fetch papers", "retrieve papers", "database search" | "ë…¼ë¬¸ ìˆ˜ì§‘", "ë…¼ë¬¸ ê²€ìƒ‰", "ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰" | sonnet |
| `diverga:i2` | "screen papers", "PRISMA screening", "inclusion criteria" | "ë…¼ë¬¸ ìŠ¤í¬ë¦¬ë‹", "ì„ ë³„", "í¬í•¨ ê¸°ì¤€" | sonnet |
| `diverga:i3` | "build RAG", "vector database", "embed documents" | "RAG êµ¬ì¶•", "ë²¡í„° DB", "ë¬¸ì„œ ìž„ë² ë”©" | haiku |

### Parallel Execution Groups

Diverga can run multiple agents in parallel when tasks are independent:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PARALLEL EXECUTION GROUPS                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Group 1: Research Design                                        â”‚
â”‚   diverga:a1 + diverga:a2 + diverga:a5                         â”‚
â”‚                                                                  â”‚
â”‚ Group 2: Literature & Evidence                                   â”‚
â”‚   diverga:b1 + diverga:b2 + diverga:b3                         â”‚
â”‚                                                                  â”‚
â”‚ Group 3: Meta-Analysis Pipeline                                  â”‚
â”‚   diverga:c5 â†’ diverga:c6 â†’ diverga:c7 (sequential)            â”‚
â”‚                                                                  â”‚
â”‚ Group 4: Quality Assurance                                       â”‚
â”‚   diverga:f1 + diverga:f3 + diverga:f4                         â”‚
â”‚                                                                  â”‚
â”‚ Group 5: Publication Prep                                        â”‚
â”‚   diverga:g1 + diverga:g2 + diverga:g5                         â”‚
â”‚                                                                  â”‚
â”‚ Group 6: Systematic Review Screening (NEW in v6.7)              â”‚
â”‚   diverga:i1 + diverga:i2 (parallel)                           â”‚
â”‚   diverga:i0 â†’ diverga:i1 â†’ diverga:i2 â†’ diverga:i3 (pipeline) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Sequential Execution Rules

Some agents must run in order:

```
Meta-Analysis Pipeline:
  diverga:c5 (orchestration)
    â†’ diverga:c6 (extraction)
    â†’ diverga:c7 (validation)

Humanization Pipeline:
  diverga:g5 (audit)
    â†’ diverga:g6 (humanize)
    â†’ diverga:f5 (verify)
```

### âš ï¸ Parallel Execution Prerequisite Gate

ë³‘ë ¬ ê·¸ë£¹ ì‹¤í–‰ ì „ ë°˜ë“œì‹œ:
1. ê·¸ë£¹ ë‚´ ëª¨ë“  ì—ì´ì „íŠ¸ì˜ prerequisites í•©ì§‘í•© í™•ì¸
2. ë¯¸ì™„ë£Œ ì „ì œì¡°ê±´ì€ AskUserQuestionìœ¼ë¡œ ë¨¼ì € í•´ê²°
3. ëª¨ë“  ì „ì œì¡°ê±´ í†µê³¼ í›„ì—ë§Œ ë³‘ë ¬ ì‹¤í–‰ ì‹œìž‘

ì˜ˆì‹œ: Group 2 (B1 + B2 + B3) ì‹¤í–‰ ì‹œ
  â†’ B1 requires CP_RESEARCH_DIRECTION
  â†’ B2 requires CP_RESEARCH_DIRECTION
  â†’ Union: {CP_RESEARCH_DIRECTION}
  â†’ AskUserQuestionìœ¼ë¡œ í™•ì¸ í›„ ë³‘ë ¬ ì‹¤í–‰

### Example Auto-Trigger

**User Message**: "I want to conduct a meta-analysis on AI-assisted learning. Need to extract effect sizes from 50 PDFs."

**Diverga Auto-Detection**:
```
Detected Keywords:
- "meta-analysis" â†’ diverga:c5 (MetaAnalysisMaster)
- "extract effect sizes" â†’ diverga:b3 (EffectSizeExtractor)
- "50 PDFs" â†’ diverga:b5 (ParallelDocumentProcessor)

Execution Plan:
1. [PARALLEL] diverga:c5 + diverga:b5
2. [SEQUENTIAL] diverga:c6 â†’ diverga:c7
```

---

## Memory System Commands (v8.0)

The DIVERGA Memory System provides persistent context preservation for research lifecycle continuity.

| Command | Description |
|---------|-------------|
| `/diverga:memory search "query"` | Semantic memory search |
| `/diverga:memory status` | Memory system status |
| `/diverga:memory context` | Current project context |
| `/diverga:memory history` | Recent session history |
| `/diverga:memory stats` | Memory statistics |
| `/diverga:memory export --format md` | Export to Markdown |
| `/diverga:memory export --format json` | Export to JSON |

### Auto-Behavior (Lifecycle Hooks)

The Memory System automatically captures context at critical lifecycle events:

| Hook | Trigger | Auto-Capture |
|------|---------|--------------|
| `session_start` | Conversation begins | Loads project context, recent decisions |
| `checkpoint_reached` | Human checkpoint passed | Saves decision with rationale, T-Score |
| `session_end` | Conversation ends | Generates summary, saves session record |
| `agent_completed` | Agent finishes task | Agent output, time taken, success/failure |

### Trigger Keywords

**English**: "remember", "memory", "context", "recall", "session", "checkpoint", "decision", "persist"

**Korean**: "ê¸°ì–µ", "ë§¥ë½", "ì„¸ì…˜", "ì²´í¬í¬ì¸íŠ¸"

---

## Version History

- **v8.0.1**: Installation Bug Fixes - Fixed install script path corruption, skills copy instead of symlink
- **v8.0.0**: Project Visibility Enhancement - Independent HUD statusline, simplified 3-step setup, natural language project start, docs/ auto-generation
- **v7.0.0**: Memory System v2 - 3-layer context system, checkpoint auto-trigger, cross-session persistence, decision audit trail
- **v6.9.2**: Marketplace Cache Fix - Fixed cache sync issue, comprehensive troubleshooting guide
- **v6.9.1**: Plugin Discovery Fix - Added version field to SKILL.md, removed orphaned directories, local symlinks
- **v6.8.0**: Memory System - Persistent context preservation with semantic search and lifecycle hooks
- **v6.7.0**: Systematic Review Automation - Category I agents (I0-I3) for PRISMA 2020 pipeline (44 agents total)
- **v6.6.3**: Codex CLI SKILL.md Implementation - actual skill loading via `.codex/skills/`, QUANT-005 verified
- **v6.6.2**: Multi-CLI Compatibility Edition - unified install script, NPM package (@diverga/codex-setup)
- **v6.5.0**: Parallel Execution Edition - Task tool support via `/agents/` directory
- **v6.4.0**: Plugin Marketplace Edition - `/plugin marketplace add`, auto-trigger dispatch, /diverga:setup wizard
- **v6.3.0**: Meta-Analysis Agent System - C5-MetaAnalysisMaster, C6-DataIntegrityGuard, C7-ErrorPreventionEngine (40 agents total)
- **v6.2.0**: Parallel Document Processing - B5-ParallelDocumentProcessor for batch PDF handling (37 agents total)
- **v6.1.0**: Humanization Pipeline - G5-AcademicStyleAuditor, G6-AcademicStyleHumanizer, F5-HumanizationVerifier (36 agents total)
- **v6.0.1**: Agent restructuring - 33 agents with category-based naming (A1-H2)
- **v6.0.0**: Clean Slate - Removed Sisyphus/OMC modes, mandatory checkpoints
- **v5.0.0**: Sisyphus protocol, paradigm detection, 27 agents
- **v4.0.0**: Context persistence, pipeline templates, integration hub
- **v3.2.0**: OMC integration, model routing
- **v3.0.0**: Creativity modules, user checkpoints, dynamic T-Score

---

## Developer Notes

### SKILL.md Format for Claude Code Plugins

When creating skills for Claude Code plugins, the `SKILL.md` frontmatter must follow a specific format.

**Correct Format** (works):
```yaml
---
name: skill-name
description: |
  Brief description of the skill.
  Include triggers and additional info as text here.
version: "1.0.0"
---

# Skill Title

Markdown content follows...
```

**Incorrect Format** (causes "Unknown skill" error):
```yaml
---
name: skill-name
command: /plugin:skill-name       # âŒ BREAKS parsing
category: system                  # âŒ Not supported
model_tier: medium                # âŒ Not supported
triggers:                         # âŒ Not supported
  - "keyword1"
  - "keyword2"
dependencies:                     # âŒ Not supported
  required:
    - package>=1.0
---
```

**Rules**:
1. Only `name`, `description`, `version` fields are supported
2. Put extra metadata (triggers, dependencies) in description text
3. Quote version numbers: `"1.0.0"` not `1.0.0`
4. Do NOT use `command` field - it breaks skill recognition

**Testing Skills**:
```bash
# After editing SKILL.md, sync to plugin directory:
cp ".claude/skills/your-skill/SKILL.md" \
   ~/.claude/plugins/diverga/.claude/skills/your-skill/SKILL.md

# Restart Claude Code for changes to take effect
/exit
```

### Plugin Directory Structure

```
~/.claude/plugins/diverga/
â”œâ”€â”€ .claude/
â”‚   â””â”€â”€ skills/
â”‚       â”œâ”€â”€ memory/
â”‚       â”‚   â””â”€â”€ SKILL.md          # Skill definition
â”‚       â”œâ”€â”€ research-coordinator/
â”‚       â”‚   â””â”€â”€ SKILL.md
â”‚       â””â”€â”€ ...
â”œâ”€â”€ .claude-plugin/
â”‚   â””â”€â”€ marketplace.json          # Plugin metadata
â””â”€â”€ CLAUDE.md                     # Project instructions
```
