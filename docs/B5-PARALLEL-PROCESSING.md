# B5-ParallelDocumentProcessor Documentation
# B5-ë³‘ë ¬ë¬¸ì„œì²˜ë¦¬ê¸° ë¬¸ì„œ

**Version**: 6.2.0 | **Agent ID**: B5 | **Category**: B - Literature & Evidence

---

## Quick Start / ë¹ ë¥¸ ì‹œì‘

### English

B5-ParallelDocumentProcessor solves the problem of processing large PDF collections that would crash single-threaded approaches due to context overflow.

**Problem**: Processing 100+ PDFs sequentially causes memory overflow
**Solution**: Distribute work across parallel workers

### í•œêµ­ì–´

B5-ë³‘ë ¬ë¬¸ì„œì²˜ë¦¬ê¸°ëŠ” ì»¨í…ìŠ¤íŠ¸ ì˜¤ë²„í”Œë¡œìš°ë¡œ ì¸í•´ ë‹¨ì¼ ìŠ¤ë ˆë“œ ì ‘ê·¼ ë°©ì‹ì—ì„œ ì¶©ëŒí•˜ëŠ” ëŒ€ê·œëª¨ PDF ì»¬ë ‰ì…˜ ì²˜ë¦¬ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.

**ë¬¸ì œ**: 100ê°œ ì´ìƒì˜ PDFë¥¼ ìˆœì°¨ ì²˜ë¦¬í•˜ë©´ ë©”ëª¨ë¦¬ ì˜¤ë²„í”Œë¡œìš° ë°œìƒ
**í•´ê²°**: ë³‘ë ¬ ì›Œì»¤ë“¤ì—ê²Œ ì‘ì—… ë¶„ë°°

---

## Architecture / ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  B5-ParallelDocumentProcessor                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚
â”‚                    â”‚   COORDINATOR   â”‚  (Opus)                   â”‚
â”‚                    â”‚    ì½”ë””ë„¤ì´í„°    â”‚                           â”‚
â”‚                    â”‚                 â”‚                           â”‚
â”‚                    â”‚ â€¢ Scan files    â”‚                           â”‚
â”‚                    â”‚ â€¢ Plan batches  â”‚                           â”‚
â”‚                    â”‚ â€¢ Spawn workers â”‚                           â”‚
â”‚                    â”‚ â€¢ Aggregate     â”‚                           â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚
â”‚                             â”‚                                    â”‚
â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚           â–¼                 â–¼                 â–¼                  â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚     â”‚ Worker 1  â”‚    â”‚ Worker 2  â”‚    â”‚ Worker N  â”‚  (Haiku)    â”‚
â”‚     â”‚ PDF 1-20  â”‚    â”‚ PDF 21-40 â”‚    â”‚ PDF ...   â”‚             â”‚
â”‚     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜             â”‚
â”‚           â”‚                â”‚                â”‚                    â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                            â–¼                                     â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                    â”‚   Results   â”‚                               â”‚
â”‚                    â”‚    ê²°ê³¼     â”‚                               â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## How It Works / ì‘ë™ ë°©ì‹

### Phase 1: Discovery / ë°œê²¬ ë‹¨ê³„

```python
# Scan directory and plan
files = scan_directory("/path/to/pdfs")
total_count = 127
total_size = 512 MB
estimated_time = "15-20 minutes"
```

### Phase 2: Planning / ê³„íš ë‹¨ê³„

```python
# Determine optimal configuration
workers = 5
batch_size = 26  # PDFs per worker
worker_model = "haiku"  # Fast and cost-effective
```

### Phase 3: Parallel Execution / ë³‘ë ¬ ì‹¤í–‰ ë‹¨ê³„

```xml
<!-- Single message with multiple Task = Parallel execution -->
<function_calls>
  <invoke name="Task">Worker 1: PDFs 1-26</invoke>
  <invoke name="Task">Worker 2: PDFs 27-52</invoke>
  <invoke name="Task">Worker 3: PDFs 53-78</invoke>    â† All run simultaneously
  <invoke name="Task">Worker 4: PDFs 79-104</invoke>
  <invoke name="Task">Worker 5: PDFs 105-127</invoke>
</function_calls>
```

### Phase 4: Aggregation / ì§‘ê³„ ë‹¨ê³„

```python
# Combine results from all workers
results = merge(worker_1, worker_2, ..., worker_n)
failed = identify_failures()
retry(failed) if enabled
generate_report()
```

---

## Performance Comparison / ì„±ëŠ¥ ë¹„êµ

| PDF Count | Sequential | Parallel (5 workers) | Speedup |
|-----------|------------|---------------------|---------|
| 10 | 5 min | 1.5 min | **3.3x** |
| 50 | 25 min | 6 min | **4.2x** |
| 100 | 50 min | 12 min | **4.2x** |
| 200 | 100 min | 25 min | **4.0x** |

---

## Worker Types / ì›Œì»¤ ìœ í˜•

| Type | Model | Batch Size | Use Case |
|------|-------|------------|----------|
| **Light** | Haiku | 20 PDFs | Metadata, abstracts |
| **Standard** | Sonnet | 10 PDFs | Full text, tables |
| **Heavy** | Opus | 5 PDFs | Complex analysis |

---

## Trigger Keywords / íŠ¸ë¦¬ê±° í‚¤ì›Œë“œ

| English | Korean |
|---------|--------|
| "batch PDF" | "ë°°ì¹˜ PDF" |
| "parallel reading" | "ë³‘ë ¬ ì²˜ë¦¬" |
| "multiple PDFs" | "ì—¬ëŸ¬ PDF" |
| "large document" | "ëŒ€ìš©ëŸ‰ ë¬¸ì„œ" |
| "bulk extraction" | "ì¼ê´„ ì¶”ì¶œ" |

---

## Input/Output Schema

### Input

```yaml
Required:
  - pdf_directory: "/path/to/pdfs"
  - extraction_task: "full_text | abstract | metadata | tables"

Optional:
  - max_workers: 5  # default, max 10
  - batch_size: 10  # PDFs per worker
  - output_format: "json | csv | markdown"
  - retry_failed: true
```

### Output

```json
{
  "summary": {
    "total_files": 127,
    "successful": 124,
    "failed": 3,
    "processing_time": "14m 32s"
  },
  "results": [
    {
      "file": "smith_2021.pdf",
      "status": "success",
      "extracted_data": {...}
    }
  ],
  "failed_files": [
    {
      "file": "scan_2019.pdf",
      "reason": "OCR required"
    }
  ]
}
```

---

## Error Handling / ì—ëŸ¬ ì²˜ë¦¬

| Error | Recovery Strategy |
|-------|------------------|
| Memory overflow | Reduce batch size, use Light worker |
| Corrupted PDF | Skip and log, continue with others |
| Timeout | Retry with extended timeout |
| OCR needed | Flag for preprocessing |
| Password protected | Skip and notify user |

---

## Integration with Other Agents / ë‹¤ë¥¸ ì—ì´ì „íŠ¸ì™€ ì—°ë™

### Upstream (provides data to B5)

```
B1-SystematicLiteratureScout â†’ B5
  Provides: PDF list from search
```

### Downstream (receives data from B5)

```
B5 â†’ B2-EvidenceQualityAppraiser
  Provides: Extracted text for quality assessment

B5 â†’ B3-EffectSizeExtractor
  Provides: Statistical sections for effect size extraction

B5 â†’ E1-QuantitativeAnalysisGuide
  Provides: Aggregated data for analysis
```

---

## Usage Examples / ì‚¬ìš© ì˜ˆì‹œ

### Example 1: Systematic Review

```
User: "Process all 127 PDFs in my SR folder"

B5 Response:
"Scanning systematic review folder...

ğŸ“Š Discovery Results:
- Total PDFs: 127
- Total size: 512 MB
- Estimated time: 15-20 minutes

Configuration:
- Workers: 5 (Haiku)
- Batch size: 26 per worker

Worker Progress:
[W1] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 80% (21/26)
[W2] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 60% (16/26)
[W3] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% âœ“
[W4] â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 40% (11/26)
[W5] â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 80% (21/26)

Overall: 95/127 (75%) | ETA: 5 min"
```

### Example 2: Targeted Extraction (íš¨ê³¼í¬ê¸° ì¶”ì¶œ)

```
User: "ë©”íƒ€ë¶„ì„ ë…¼ë¬¸ë“¤ì—ì„œ í‘œë³¸í¬ê¸°ì™€ íš¨ê³¼í¬ê¸°ë§Œ ì¶”ì¶œí•´ì¤˜"

B5 Configuration:
  extraction_task: specific_sections
  fields: ["sample_size", "effect_size", "CI"]
  output_format: csv

Output:
file,sample_size,effect_size,effect_type
smith_2021.pdf,1234,0.45,Cohen's d
wang_2022.pdf,567,0.62,Hedge's g
```

### Example 3: Large Single File (ëŒ€ìš©ëŸ‰ ë‹¨ì¼ íŒŒì¼)

```
User: "500í˜ì´ì§€ ë°•ì‚¬ë…¼ë¬¸ì´ ìê¾¸ í¬ë˜ì‹œë¼ìš”"

B5 Strategy:
1. Split into 50-page chunks
2. Process chunks in parallel
3. Reassemble in order

Result: Processed in 8-12 minutes instead of crash
```

---

## Configuration Presets / ì„¤ì • í”„ë¦¬ì…‹

### Default (Balanced)

```yaml
workers: 5
batch_size: 10
worker_model: haiku
timeout: 60s
retry: true
```

### Memory-Safe (ë©”ëª¨ë¦¬ ì•ˆì „)

```yaml
workers: 3
batch_size: 5
worker_model: haiku
timeout: 120s
retry: true
```

### Maximum Speed (ìµœëŒ€ ì†ë„)

```yaml
workers: 10
batch_size: 20
worker_model: haiku
timeout: 30s
retry: false
```

---

## Checkpoints / ì²´í¬í¬ì¸íŠ¸

| Checkpoint | Level | When |
|------------|-------|------|
| CP-INIT-001 | ğŸ”´ Required | Before processing - confirm file count |
| CP-PROGRESS-001 | ğŸŸ  Recommended | At 50% - allow adjustment |
| CP-COMPLETE-001 | ğŸŸ¡ Optional | After processing - review results |

---

## Related Documentation / ê´€ë ¨ ë¬¸ì„œ

- [MECHANISM.md](../.claude/skills/research-agents/B5-parallel-document-processor/MECHANISM.md) - Detailed implementation
- [workflow-parallel-pdf.md](../.claude/skills/research-agents/B5-parallel-document-processor/workflow-parallel-pdf.md) - Workflow details
- [README-ko.md](../.claude/skills/research-agents/B5-parallel-document-processor/README-ko.md) - Korean guide
- [AGENT-ORCHESTRATION-GUIDE.md](./AGENT-ORCHESTRATION-GUIDE.md) - Full orchestration guide
