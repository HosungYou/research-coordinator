# Academic-Specific, Communication, and Filler Patterns
# Patterns specific to scholarly writing and AI communication artifacts
# Categories: M (Communication), H (Hedging/Filler), A (Academic-Specific)

version: "1.0.0"
category: "academic_combined"
pattern_count: 12

# Communication Patterns (M1-M3)
communication_patterns:
  M1:
    name: "Chatbot Artifacts"
    risk_level: "high"
    description: |
      Conversational scaffolding that leaks from chat AI into static documents.
      These phrases are appropriate in conversation but never in academic writing.

    indicators:
      phrases:
        # Help/assistance phrases
        - "I hope this helps"
        - "Let me know if you"
        - "Feel free to ask"
        - "I'd be happy to"
        - "If you have any questions"
        - "Don't hesitate to"

        # Explanation scaffolding
        - "Let me explain"
        - "To put it simply"
        - "In other words"
        - "To clarify"
        - "Allow me to"
        - "I'll walk you through"

        # Agreement/acknowledgment
        - "That's a great question"
        - "Absolutely!"
        - "Certainly!"
        - "Of course!"
        - "Great point!"

        # First person AI references
        - "As an AI"
        - "As a language model"
        - "I cannot"
        - "I don't have access to"
        - "Based on my training"

    academic_context:
      always_remove: true
      exception: "Direct quotes from interviews"

    transformations:
      recommendation: "Remove entirely; academic writing doesn't address reader directly"

  M2:
    name: "Knowledge-Cutoff Disclaimers"
    risk_level: "high"
    description: |
      AI disclosure of its limitations that appears in generated text.
      Dead giveaway of AI authorship.

    indicators:
      phrases:
        - "As of my last training"
        - "As of my knowledge cutoff"
        - "While I don't have access to"
        - "specific details are limited"
        - "I cannot verify"
        - "updated information may be available"
        - "since my training data"
        - "my information may be outdated"
        - "according to my training"
        - "within my training data"

    academic_context:
      always_remove: true
      note: "These reveal AI authorship directly"

    transformations:
      recommendation: "Remove and verify claims with actual sources"

  M3:
    name: "Sycophantic Tone"
    risk_level: "medium"
    description: |
      Overly agreeable, validating language that signals AI's tendency
      to please users rather than provide objective analysis.

    indicators:
      phrases:
        - "That's an excellent point"
        - "You raise a very important"
        - "Great question!"
        - "Absolutely right"
        - "Very insightful"
        - "Brilliant observation"
        - "You've touched on"
        - "Your approach is sound"

      tone_markers:
        - Excessive agreement without critique
        - Validating phrases before every response
        - Avoiding any disagreement

    academic_context:
      acceptable_when:
        - "Response letters acknowledging valid reviewer points (limited use)"

      flag_when:
        - "Main body text"
        - "Objective analysis sections"
        - "Multiple instances"

    transformations:
      "That's an excellent point": "This point is valid"
      "Great observation": (remove or) "This observation..."
      "You've touched on an important issue": "This issue..."

# Filler and Hedging Patterns (H1-H3)
filler_patterns:
  H1:
    name: "Verbose Phrases"
    risk_level: "low"
    description: |
      Unnecessarily wordy constructions that add length without meaning.
      AI tends toward verbosity as a "safer" strategy.

    indicators:
      verbose_to_concise:
        "in order to": "to"
        "for the purpose of": "to"
        "with the aim of": "to"
        "in an effort to": "to"
        "at this point in time": "now"
        "at the present time": "now"
        "in the current study": (remove) "This study"
        "due to the fact that": "because"
        "owing to the fact that": "because"
        "by virtue of the fact that": "because"
        "despite the fact that": "although"
        "in spite of the fact that": "although"
        "it is important to note that": (remove)
        "it should be noted that": (remove)
        "it is worth mentioning that": (remove)
        "it goes without saying that": (remove)
        "needless to say": (remove)
        "a large number of": "many"
        "a small number of": "few"
        "the majority of": "most"
        "in close proximity to": "near"
        "has the ability to": "can"
        "is able to": "can"
        "in the event that": "if"
        "on the basis of": "based on"

    academic_context:
      acceptable_when:
        - "Never - these are always improvable"

    transformations:
      # Direct replacements as shown in indicators

  H2:
    name: "Excessive Hedging"
    risk_level: "medium"
    description: |
      Stacking multiple qualifiers dilutes claims and signals uncertainty
      that may not be warranted. AI over-hedges to avoid seeming confident.

    indicators:
      hedge_words:
        - "may"
        - "might"
        - "could"
        - "possibly"
        - "potentially"
        - "perhaps"
        - "seemingly"
        - "apparently"
        - "presumably"
        - "somewhat"
        - "relatively"
        - "to some extent"
        - "in some ways"
        - "more or less"

      stacking_patterns:
        - "could potentially"      # Double hedge
        - "may possibly"           # Double hedge
        - "might potentially"      # Double hedge
        - "could possibly perhaps" # Triple hedge
        - "seems to suggest"       # Double hedge
        - "appears to indicate"    # Double hedge
        - "may potentially possibly" # Triple hedge

      threshold:
        per_sentence: 2  # More than 2 hedges = flag
        per_paragraph: 4

    academic_context:
      acceptable_when:
        - "Discussing limitations"
        - "Speculating about mechanisms"
        - "Single appropriate hedge"

      not_acceptable:
        - "Stacked hedges (2+ in same phrase)"
        - "Hedging established findings"
        - "Hedging your own clear results"

    transformations:
      "could potentially": "may"
      "may possibly": "may"
      "might potentially": "might"
      "seems to suggest": "suggests"
      "appears to indicate": "indicates"
      general_rule: "Use single appropriate hedge; remove stacking"

  H3:
    name: "Generic Conclusions"
    risk_level: "medium"
    description: |
      Template-like ending statements that could apply to any study.
      AI cannot generate specific future directions, so it uses generics.

    indicators:
      phrases:
        # Future research
        - "Future research is needed"
        - "Further research should explore"
        - "More studies are warranted"
        - "Additional research is required"
        - "This warrants further investigation"

        # Implications
        - "These findings have important implications"
        - "The implications are far-reaching"
        - "This has significant implications for"

        # Positive outlook
        - "The future looks promising"
        - "Exciting opportunities await"
        - "This opens new avenues"
        - "This paves the way for"

        # Generic importance
        - "This is an important area"
        - "This is a growing field"
        - "This deserves attention"

    academic_context:
      acceptable_when:
        - "Followed by specific research questions"
        - "Accompanied by concrete next steps"
        - "Within broader specific discussion"

      not_acceptable:
        - "Standalone generic statement"
        - "As final sentence without specifics"
        - "Multiple generic conclusions in same section"

    transformations:
      "Future research is needed": "Future research should examine [specific question]"
      "These findings have important implications": "These findings suggest that [specific implication]"
      "This opens new avenues": "[Specific avenue] becomes feasible"
      rule: "Replace generic with specific; name concrete next steps"

# Academic-Specific Patterns (A1-A6)
academic_specific_patterns:
  A1:
    name: "Abstract Template Filling"
    risk_level: "low"
    description: |
      Rigid adherence to abstract templates without natural flow.
      AI often produces formulaic "This paper aims to..." structures.

    indicators:
      template_phrases:
        - "This paper aims to"
        - "This study aims to"
        - "The purpose of this study is to"
        - "The aim of this research is to"
        - "This paper seeks to"
        - "This research endeavors to"
        - "The present study investigates"
        - "The current research examines"

      structural_markers:
        - Every abstract sentence starts with "This"
        - Exact IMRAD mirroring without flow
        - Mechanical transition between sections

    academic_context:
      partially_acceptable: true
      note: "Some template structure is expected in abstracts"

      flag_when:
        - "Every sentence starts with 'This study'"
        - "No variation in structure"
        - "Reads like form-filling rather than summary"

    transformations:
      "This paper aims to examine": "We examined"
      "The purpose of this study is to": "This study"
      "The present study investigates": "We investigated"
      variation_suggestions:
        - "Vary sentence openings"
        - "Use active voice"
        - "Lead with finding, not purpose"

  A2:
    name: "Methods Boilerplate"
    risk_level: "low"
    description: |
      Generic methodology descriptions that lack study-specific detail.
      AI cannot know actual methodology, so it produces boilerplate.

    indicators:
      phrases:
        - "Data were analyzed using"
        - "Statistical analyses were performed"
        - "Qualitative analysis was conducted"
        - "The data were collected through"
        - "Participants were recruited from"
        - "The study followed ethical guidelines"
        - "Informed consent was obtained"

      red_flags:
        - Generic software mention without version
        - No specific statistical tests named
        - Vague participant description
        - Missing sample size justification

    academic_context:
      partially_acceptable: true
      note: "Methods have legitimate standard phrases"

      flag_when:
        - "Missing critical details (N, specific tests, software versions)"
        - "Could describe any study in the field"
        - "No study-specific customization"

    transformations:
      "Data were analyzed": "We analyzed data using [specific method]"
      "Statistical analyses were performed": "[Specific test] was used to..."
      rule: "Add specific details: N, software version, exact tests, parameters"

  A3:
    name: "Discussion Inflation"
    risk_level: "medium"
    description: |
      Overclaiming the implications or significance of findings.
      AI tends to amplify importance without evidence.

    indicators:
      phrases:
        - "These findings revolutionize"
        - "This fundamentally changes"
        - "unprecedented implications"
        - "far-reaching consequences"
        - "transforms our understanding"
        - "reshapes the field"
        - "paradigm shift"

      patterns:
        - Jumping from specific finding to broad claim
        - Claiming field-wide impact from single study
        - Suggesting practice changes without replication

    academic_context:
      acceptable_when:
        - "Never without substantial evidence"
        - "Only for truly breakthrough findings"

    transformations:
      "revolutionizes": "advances"
      "fundamentally changes": "contributes to"
      "unprecedented": "novel"
      "transforms": "informs"
      rule: "Match claim magnitude to evidence strength"

  A4:
    name: "Citation Hedging"
    risk_level: "medium"
    description: |
      Vague references to literature without actual citations.
      AI cannot cite real sources, so it hedges with generalizations.

    indicators:
      phrases:
        - "Previous studies have shown"
        - "The literature suggests"
        - "Research indicates"
        - "It has been established that"
        - "Studies have found"
        - "According to research"
        - "As documented in the literature"

      red_flag: "Any of these WITHOUT immediate citation"

    academic_context:
      acceptable_when:
        - "Immediately followed by (Author, year)"
        - "Multiple citations follow"
        - "In introduction summarizing consensus"

      always_flag:
        - "No citation within sentence or next sentence"
        - "Multiple uses without any citation"

    transformations:
      "Previous studies have shown": "[Author1, year; Author2, year] found"
      "The literature suggests": "[Review by Author, year] suggests"
      "Research indicates": "[Citation] indicates"
      rule: "Add specific citations or remove claim"

  A5:
    name: "Contribution Enumeration"
    risk_level: "low"
    description: |
      Listing contributions in numbered format that feels mechanical.
      AI loves to enumerate "First, Second, Third" contributions.

    indicators:
      patterns:
        - "This study makes several contributions. First,... Second,... Third,..."
        - "The contributions of this paper are threefold"
        - "This research contributes to the literature in three ways"
        - "Our contributions include: (1)... (2)... (3)..."

      characteristics:
        - Always exactly three contributions
        - Contributions are abstract (not specific findings)
        - Third contribution often weakest/repetitive

    academic_context:
      acceptable_when:
        - "Contributions are genuinely distinct"
        - "Introduction section in some fields"
        - "Journal style encourages enumeration"

      flag_when:
        - "Forced into three when two or four fit better"
        - "Third contribution is filler"
        - "Abstract contributions rather than concrete findings"

    transformations:
      rule: "State contributions naturally; remove artificial enumeration if forced"
      example_before: |
        This study makes three contributions. First, we examine X. Second, we analyze Y. Third, we explore Z.
      example_after: |
        This study examines X and analyzes Y, with particular attention to Z.

  A6:
    name: "Limitation Disclaimers"
    risk_level: "low"
    description: |
      Generic limitation statements that could apply to any study.
      AI produces boilerplate limitations without study-specific insight.

    indicators:
      phrases:
        - "This study has several limitations"
        - "The findings should be interpreted with caution"
        - "Generalizability may be limited"
        - "Future research should address these limitations"
        - "Despite these limitations"
        - "Notwithstanding these limitations"

      generic_limitations:
        - "Sample size"
        - "Generalizability"
        - "Cross-sectional design"
        - "Self-report measures"
        # Without specific explanation of impact

    academic_context:
      partially_acceptable: true
      note: "Limitations section is expected"

      flag_when:
        - "Generic list without study-specific impact"
        - "No explanation of how limitation affects findings"
        - "Boilerplate that could describe any study"

    transformations:
      "This study has several limitations": (specify) "[Limitation X] may have affected..."
      rule: "Explain HOW each limitation specifically affects THIS study's findings"

# Scoring Summary
scoring:
  communication:
    M1_chatbot: 20  # High penalty - obvious AI
    M2_cutoff: 25   # Very high - direct disclosure
    M3_sycophantic: 8

  filler:
    H1_verbose: 2   # Per instance
    H2_hedge_stack: 6  # Per stacked hedge
    H3_generic: 5

  academic:
    A1_template: 3
    A2_boilerplate: 3
    A3_inflation: 10
    A4_citation_hedge: 12  # High - academic integrity
    A5_enumeration: 2
    A6_limitation: 2
