#!/usr/bin/env python3
"""
Diverga QA Protocol v2.1 - Automated Test Simulator

Simulates conversations based on protocol YAML files and records all interactions.
Does NOT require manual user input - runs completely automatically.

Usage:
    python automated_test.py --scenario QUAL-002 --output qa/reports/sessions/
"""

import argparse
import json
import yaml
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass, field, asdict
from typing import Optional, List, Dict, Any


@dataclass
class SimulatedTurn:
    """A simulated conversation turn."""
    turn_number: int
    user_type: str
    user_input: str
    user_input_ko: Optional[str]  # Korean version if applicable
    expected_behavior: Dict[str, Any]
    simulated_response: str
    checkpoints_triggered: List[str] = field(default_factory=list)
    agents_invoked: List[str] = field(default_factory=list)
    validation_passed: bool = True
    validation_notes: List[str] = field(default_factory=list)


@dataclass
class TestSession:
    """Complete test session."""
    scenario_id: str
    scenario_name: str
    language: str
    paradigm: str
    started_at: str
    completed_at: Optional[str] = None
    turns: List[SimulatedTurn] = field(default_factory=list)
    total_checkpoints: int = 0
    checkpoints_passed: int = 0
    agents_invoked: List[str] = field(default_factory=list)
    overall_passed: bool = True
    summary: Dict[str, Any] = field(default_factory=dict)


class AutomatedTestSimulator:
    """
    Simulates Diverga conversations based on protocol YAML.

    This is a SIMULATION - it generates realistic responses based on
    expected behaviors without calling actual agents. Used for QA testing
    and demonstration purposes.
    """

    PROTOCOL_DIR = Path(__file__).parent.parent / "protocol"

    # Simulated responses for each scenario
    RESPONSE_TEMPLATES = {
        "QUAL-002": {
            1: """## ğŸ” íŒ¨ëŸ¬ë‹¤ì„ ê°ì§€

ì—°êµ¬ ë§¥ë½ì—ì„œ **ì§ˆì  ì—°êµ¬(Qualitative)** ì ‘ê·¼ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤:

| ê°ì§€ëœ í‚¤ì›Œë“œ | ì‹ í˜¸ |
|--------------|------|
| "ê²½í—˜í•˜ëŠ” í˜„ìƒ" | í˜„ìƒí•™ì  íƒêµ¬ |
| "íƒêµ¬í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤" | íƒìƒ‰ì  ì—°êµ¬ |
| "ì–´ë–»ê²Œ...í†µí•©í•˜ëŠ”ì§€" | ê³¼ì • ì´í•´ |
| "ê¸´ì¥ê³¼ ê°ˆë“±" | ì£¼ê´€ì  ê²½í—˜ |

---

## ğŸ”´ CHECKPOINT: CP_PARADIGM_SELECTION

**ì—°êµ¬ ë°©ë²•ë¡ ì  ì ‘ê·¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”:**

| ì˜µì…˜ | ë°©ë²•ë¡  | T-Score | ì„¤ëª… |
|------|--------|---------|------|
| **[A]** | ê¸°ìˆ ì  í˜„ìƒí•™ (Descriptive Phenomenology) | T=0.55 | Husserl ì „í†µ, ì—í¬ì¼€(bracketing)ë¥¼ í†µí•œ ìˆœìˆ˜ ê²½í—˜ ê¸°ìˆ  |
| **[B]** | í•´ì„í•™ì  í˜„ìƒí•™ (Hermeneutic Phenomenology) | T=0.40 â­ | van Manen ì ‘ê·¼, ì²´í—˜ì˜ ì˜ë¯¸ í•´ì„ - êµìœ¡ ì—°êµ¬ì— ì í•© |
| **[C]** | í•´ì„ì  í˜„ìƒí•™ ë¶„ì„ (IPA) | T=0.45 | Smith ì ‘ê·¼, ê°œë³„ ì‚¬ë¡€ì˜ ì‹¬ì¸µ ë¶„ì„ |
| **[D]** | ë‚´ëŸ¬í‹°ë¸Œ íƒêµ¬ (Narrative Inquiry) | T=0.35 | Clandinin & Connelly, êµì‚¬ ì´ì•¼ê¸° ì¤‘ì‹¬ |

**ì–´ë–¤ ë°©ë²•ë¡ ìœ¼ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?**""",

            2: """## í˜„ìƒí•™ì  ì ‘ê·¼ë²• ë¹„êµ: Husserl vs Heidegger vs van Manen

í›Œë¥­í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤. ì„¸ ì ‘ê·¼ë²•ì˜ í•µì‹¬ì ì¸ ì°¨ì´ë¥¼ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

### 1. Husserlì˜ ê¸°ìˆ ì  í˜„ìƒí•™ (Descriptive Phenomenology)

**í•µì‹¬ ê°œë…: ì—í¬ì¼€(EpochÃ©) / íŒë‹¨ì¤‘ì§€(Bracketing)**

- ì—°êµ¬ìì˜ ì„ ì…ê²¬, ì´ë¡ , ê°€ì •ì„ "ê´„í˜¸ ì•ˆì— ë„£ì–´" ì¤‘ì§€
- **ìˆœìˆ˜í•œ ì˜ì‹ ê²½í—˜**ì— ë„ë‹¬í•˜ê³ ì í•¨
- í˜„ìƒì„ "ìˆëŠ” ê·¸ëŒ€ë¡œ" ê¸°ìˆ í•˜ëŠ” ê²ƒì´ ëª©í‘œ

**ì‹¤ì œ ì—°êµ¬ ì ìš©:**
```
ì—°êµ¬ì: "AI ë„êµ¬ì— ëŒ€í•œ ë‚˜ì˜ ê²½í—˜ê³¼ ì˜ê²¬ì„ ì ì‹œ ë©ˆì¶”ê³ ,
        êµì‚¬ë“¤ì´ ê²½í—˜í•˜ëŠ” í˜„ìƒ ìì²´ì—ë§Œ ì§‘ì¤‘í•œë‹¤."
```

### 2. Heideggerì˜ í•´ì„í•™ì  í˜„ìƒí•™

**í•µì‹¬ ê°œë…: ì„ ì´í•´(Fore-understanding) / í•´ì„í•™ì  ìˆœí™˜(Hermeneutic Circle)**

- ì™„ì „í•œ bracketingì€ **ë¶ˆê°€ëŠ¥**í•˜ë‹¤ê³  ë´„
- ì—°êµ¬ìì˜ ì„ ì´í•´ê°€ í•´ì„ì— **í•„ìˆ˜ì **
- ë¶€ë¶„ê³¼ ì „ì²´ ì‚¬ì´ë¥¼ ì˜¤ê°€ë©° ì´í•´ë¥¼ ì‹¬í™”

**ì‹¤ì œ ì—°êµ¬ ì ìš©:**
```
ì—°êµ¬ì: "ë‚˜ì˜ êµìœ¡í•™ ë°°ê²½ê³¼ AI ê²½í—˜ì´ êµì‚¬ë“¤ì˜ ê²½í—˜ì„
        ì´í•´í•˜ëŠ” ë° ì˜¤íˆë ¤ ë„ì›€ì´ ëœë‹¤. ì´ë¥¼ ëª…ì‹œì ìœ¼ë¡œ
        ë“œëŸ¬ë‚´ê³  í•´ì„ì— í™œìš©í•œë‹¤."
```

### 3. van Manenì˜ í•´ì„í•™ì  í˜„ìƒí•™ (êµìœ¡í•™ ì¤‘ì‹¬)

**í•µì‹¬ ê°œë…: ì²´í—˜(Lived Experience) / ìƒí™œì„¸ê³„(Lifeworld)**

- Heideggerì˜ í•´ì„í•™ + êµìœ¡í•™ì  ê´€ì 
- **êµìœ¡ì  ì‹¤ì²œ**ì— ëŒ€í•œ ë°˜ì„±ì  ì´í•´
- ë„¤ ê°€ì§€ ìƒí™œì„¸ê³„ ì‹¤ì¡´ì²´:
  - ì²´í—˜ëœ ê³µê°„ (spatiality)
  - ì²´í—˜ëœ ëª¸ (corporeality)
  - ì²´í—˜ëœ ì‹œê°„ (temporality)
  - ì²´í—˜ëœ ê´€ê³„ (relationality)

**ì‹¤ì œ ì—°êµ¬ ì ìš©:**
```
ì—°êµ¬ì: "êµì‚¬ê°€ AI ë„êµ¬ë¥¼ ì‚¬ìš©í•  ë•Œì˜ 'ì²´í—˜ëœ ê³µê°„'ì€ ì–´ë– í•œê°€?
        ë””ì§€í„¸ ê³µê°„ê³¼ ë¬¼ë¦¬ì  êµì‹¤ ì‚¬ì´ì—ì„œ ì–´ë–¤ ê¸´ì¥ì„ ëŠë¼ëŠ”ê°€?"
```

---

### ì„ ìƒë‹˜ì˜ ì—°êµ¬ì— ëŒ€í•œ ê¶Œì¥

**van Manen ì ‘ê·¼ì´ ê°€ì¥ ì í•©í•œ ì´ìœ :**

1. **êµìœ¡ ë§¥ë½ íŠ¹í™”**: van Manenì€ êµìœ¡í•™ìë¡œì„œ êµì‚¬ ê²½í—˜ ì—°êµ¬ì— ìµœì í™”
2. **ì‹¤ì²œì  ì§€í–¥**: "êµìœ¡ì² í•™ê³¼ì˜ í†µí•©"ì´ë¼ëŠ” ì—°êµ¬ ê´€ì‹¬ê³¼ ì¼ì¹˜
3. **ê¸´ì¥ê³¼ ê°ˆë“± í•´ì„**: ìƒí™œì„¸ê³„ ê°œë…ìœ¼ë¡œ ë‹¤ì¸µì  í•´ì„ ê°€ëŠ¥
4. **í•œêµ­ êµìœ¡ì—°êµ¬ í™œìš©**: êµ­ë‚´ êµìœ¡í•™ ë…¼ë¬¸ì—ì„œ ë„ë¦¬ ì‚¬ìš©

**IPAì™€ì˜ ì°¨ì´:**
- IPA: ê°œì¸ë³„ ì‹¬ì¸µ ì‚¬ë¡€ ë¶„ì„, ì‹¬ë¦¬í•™ì  ë°°ê²½
- van Manen: ë³¸ì§ˆì  ì£¼ì œ ë„ì¶œ, êµìœ¡í•™ì  ë°°ê²½

---

ğŸ”´ **ì²´í¬í¬ì¸íŠ¸ ìœ ì§€ ì¤‘**: ë°©ë²•ë¡  ì„ íƒì„ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤.
`[A]`, `[B]`, `[C]`, `[D]` ì¤‘ ì„ íƒí•´ ì£¼ì„¸ìš”.""",

            3: """## âœ… ì„ íƒ ì™„ë£Œ: [B] í•´ì„í•™ì  í˜„ìƒí•™ (van Manen)

ì„ íƒì´ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì„ íƒëœ ë°©ë²•ë¡ ** | í•´ì„í•™ì  í˜„ìƒí•™ (van Manen) |
| **T-Score** | 0.40 (ì°¨ë³„í™”ëœ ì ‘ê·¼) |
| **ê´€ë ¨ ì—ì´ì „íŠ¸** | C2-QualitativeDesignConsultant |

---

## ğŸ”´ CHECKPOINT: CP_METHODOLOGY_APPROVAL

**ì—°êµ¬ ì„¤ê³„ ì´ˆì•ˆì„ ì œì‹œí•©ë‹ˆë‹¤:**

### ì—°êµ¬ ì„¤ê³„ ê°œìš”

| êµ¬ì„±ìš”ì†Œ | ë‚´ìš© |
|----------|------|
| **ì—°êµ¬ ì§ˆë¬¸** | êµì‚¬ë“¤ì€ AI ë„êµ¬ë¥¼ êµìœ¡ ì² í•™ê³¼ í†µí•©í•˜ëŠ” ê³¼ì •ì—ì„œ ì–´ë–¤ ì²´í—˜ì„ í•˜ëŠ”ê°€? |
| **ë°©ë²•ë¡ ** | van Manenì˜ í•´ì„í•™ì  í˜„ìƒí•™ |
| **ì°¸ì—¬ì** | AI ë„êµ¬ ì‚¬ìš© ê²½í—˜ì´ ìˆëŠ” K-12 êµì‚¬ |
| **ìë£Œ ìˆ˜ì§‘** | ì‹¬ì¸µ ì¸í„°ë·° (60-90ë¶„, 2-3íšŒ) |
| **ë¶„ì„ ë°©ë²•** | ì£¼ì œ ë¶„ì„ (Thematic Analysis) |

### ìƒí™œì„¸ê³„ íƒêµ¬ í”„ë ˆì„ì›Œí¬

1. **ì²´í—˜ëœ ê³µê°„**: ë””ì§€í„¸/ë¬¼ë¦¬ì  êµì‹¤ ê³µê°„ì˜ ê²½í—˜
2. **ì²´í—˜ëœ ëª¸**: AI ë„êµ¬ ì‚¬ìš© ì‹œ êµì‚¬ë¡œì„œì˜ ì •ì²´ì„±
3. **ì²´í—˜ëœ ì‹œê°„**: ìˆ˜ì—… ì¤€ë¹„, ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš©ì˜ ë³€í™”
4. **ì²´í—˜ëœ ê´€ê³„**: í•™ìƒ, ë™ë£Œ, ê¸°ìˆ ê³¼ì˜ ê´€ê³„ ë³€í™”

**ì´ ì„¤ê³„ë¡œ ì§„í–‰í•´ë„ ë ê¹Œìš”?**""",

            4: """## ğŸ”„ Agent Transition: A3-DevilsAdvocate

ë¹„íŒì  ê²€í† ë¥¼ ìœ„í•´ A3-DevilsAdvocate ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.

---

## ğŸ‘¿ Devil's Advocate: IPA vs van Manen ë¹„íŒì  ê²€í† 

### Reviewer 2ê°€ ë¬¼ì„ ìˆ˜ ìˆëŠ” ì§ˆë¬¸ë“¤

**Q1: "ì™œ IPA ëŒ€ì‹  van Manenì„ ì„ íƒí–ˆìŠµë‹ˆê¹Œ?"**

ì˜ˆìƒ ë¹„íŒ:
- "IPAê°€ ë” ì²´ê³„ì ì¸ ë¶„ì„ ì ˆì°¨ë¥¼ ì œê³µí•©ë‹ˆë‹¤"
- "IPAëŠ” ì‹¬ë¦¬í•™ì  ê¹Šì´ê°€ ë” ìˆìŠµë‹ˆë‹¤"
- "van Manenì€ ë¶„ì„ ì ˆì°¨ê°€ ëª¨í˜¸í•©ë‹ˆë‹¤"

**ë°©ì–´ ì „ëµ:**
```
"IPAëŠ” ê°œì¸ì˜ ì˜ë¯¸ í˜•ì„±(sense-making)ì— ì´ˆì ì„ ë‘ì§€ë§Œ,
ë³¸ ì—°êµ¬ëŠ” êµì‚¬ì˜ 'êµìœ¡ì  ì‹¤ì²œ'ì— ëŒ€í•œ ë°˜ì„±ì  ì´í•´ë¥¼ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.
van Manenì˜ ì ‘ê·¼ì€ êµìœ¡í•™ì  ë§¥ë½ì—ì„œ ê°œë°œë˜ì–´
êµì‚¬ ê²½í—˜ ì—°êµ¬ì— ë” ì í•©í•©ë‹ˆë‹¤ (van Manen, 1990, 2014)."
```

**Q2: "van Manen ì ‘ê·¼ë²•ì˜ ë¶„ì„ ì ˆì°¨ê°€ ë¶ˆëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆê¹Œ?"**

ì˜ˆìƒ ë¹„íŒ:
- "IPAì˜ 6ë‹¨ê³„ ë¶„ì„ì´ ë” íˆ¬ëª…í•©ë‹ˆë‹¤"
- "ì¬í˜„ê°€ëŠ¥ì„±(replicability) ë¬¸ì œ"

**ë°©ì–´ ì „ëµ:**
```
"van Manen(1990)ì€ 6ê°€ì§€ ì—°êµ¬ í™œë™ì„ ì œì‹œí•©ë‹ˆë‹¤:
1. í˜„ìƒì„ í–¥í•œ ì „í™˜
2. ì²´í—˜ íƒêµ¬
3. ë³¸ì§ˆì  ì£¼ì œ ë°˜ì„±
4. ê¸€ì“°ê¸°ë¥¼ í†µí•œ íƒêµ¬
5. ê°•í•œ êµìœ¡í•™ì  ê´€ê³„ ìœ ì§€
6. ë¶€ë¶„ê³¼ ì „ì²´ì˜ ê· í˜•

ì´ëŠ” IPAì™€ ë‹¤ë¥¸ ë°©ì‹ì´ì§€ë§Œ ë™ë“±í•˜ê²Œ ì²´ê³„ì ì…ë‹ˆë‹¤."
```

### IPA ì„ íƒ ì‹œ vs van Manen ì„ íƒ ì‹œ ë…¼ë¬¸ êµ¬ì„± ì°¨ì´

| ì¸¡ë©´ | IPA | van Manen |
|------|-----|-----------|
| **ë¶„ì„ ë‹¨ìœ„** | ê°œë³„ ì‚¬ë¡€ â†’ êµì°¨ ì‚¬ë¡€ | ì „ì²´ì  ë³¸ì§ˆ ì£¼ì œ |
| **ê¸€ì“°ê¸° ìŠ¤íƒ€ì¼** | ë¶„ì„ì , í‘œ ì¤‘ì‹¬ | ì„œìˆ ì , ì¼í™”ì  |
| **ì¸ìš© ë¹ˆë„** | ê°œì¸ë³„ ë‹¤ìˆ˜ ì¸ìš© | ì£¼ì œë³„ ì„ íƒì  ì¸ìš© |
| **ì£¼ìš” í•™íšŒ** | ì‹¬ë¦¬í•™, ê±´ê°•í•™ | êµìœ¡í•™, ê°„í˜¸í•™ |

---

**ê²°ë¡ **: êµìœ¡í•™ ì €ë„ íˆ¬ê³  ì‹œ van Manenì´ ë” ìˆ˜ìš©ë„ê°€ ë†’ìŠµë‹ˆë‹¤.
Teaching and Teacher Education, Teachers and Teaching ë“±ì—ì„œ
van Manen ê¸°ë°˜ ì—°êµ¬ê°€ í™œë°œíˆ ì¶œíŒë˜ê³  ìˆìŠµë‹ˆë‹¤.""",

            5: """## ğŸ“Š í‘œë³¸ í¬ê¸° ì ì ˆì„± ê²€í† 

n=5ì— ëŒ€í•œ ìš°ë ¤ë¥¼ ì´í•´í•©ë‹ˆë‹¤. ì†”ì§í•˜ê²Œ í‰ê°€í•´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

### í˜„ìƒí•™ì  ì—°êµ¬ì˜ í‘œë³¸ í¬ê¸° ê°€ì´ë“œë¼ì¸

| í•™ì | ê¶Œì¥ | ê·¼ê±° |
|------|------|------|
| **Creswell (2013)** | 3-10ëª… | í˜„ìƒí•™ì€ ê¹Šì´ > ë²”ìœ„ |
| **Dukes (1984)** | 3-10ëª… | ë³¸ì§ˆ íƒêµ¬ì— ì¶©ë¶„ |
| **Polkinghorne (1989)** | 5-25ëª… | í˜„ìƒì˜ ë³µì¡ì„±ì— ë”°ë¼ |
| **van Manen (1990)** | ëª…ì‹œì  ê¸°ì¤€ ì—†ìŒ | ë°ì´í„° í’ë¶€ì„± ê°•ì¡° |

### n=5ê°€ ì¶©ë¶„í•œ ì¡°ê±´

âœ… **ì¶©ë¶„í•œ ê²½ìš°:**
- ê° ì°¸ì—¬ìì™€ 2-3íšŒ ì‹¬ì¸µ ì¸í„°ë·° (ì´ 10-15íšŒ ì¸í„°ë·°)
- ì¸í„°ë·°ë‹¹ 60-90ë¶„ (ì¶©ë¶„í•œ ê¹Šì´)
- ë‹¤ì–‘í•œ ë°°ê²½ (ì´ˆ/ì¤‘/ê³ , ê²½ë ¥ ë‹¤ì–‘ì„±)
- **ì£¼ì œ í¬í™”(Thematic Saturation)** ë‹¬ì„±

âš ï¸ **ë³´ì™„ì´ í•„ìš”í•œ ê²½ìš°:**
- ë‹¨ì¼ ì¸í„°ë·°ë§Œ ì§„í–‰
- ë™ì§ˆì  ì°¸ì—¬ì ì§‘ë‹¨
- 30ë¶„ ì´í•˜ì˜ ì§§ì€ ì¸í„°ë·°

### ì €ë„ Reject ìœ„í—˜ ëŒ€ì‘

**ì „ëµ 1: í‘œë³¸ í¬ê¸° ì •ë‹¹í™” ì„¹ì…˜ ì‘ì„±**
```
"í˜„ìƒí•™ì  ì—°êµ¬ì—ì„œ í‘œë³¸ í¬ê¸°ëŠ” í†µê³„ì  ì¼ë°˜í™”ê°€ ì•„ë‹Œ
í˜„ìƒì˜ ë³¸ì§ˆ íƒêµ¬ì— ì˜í•´ ê²°ì •ëœë‹¤ (Creswell, 2013).
ë³¸ ì—°êµ¬ëŠ” 5ëª…ì˜ ì°¸ì—¬ìì™€ ê° 2-3íšŒ ì‹¬ì¸µ ì¸í„°ë·°ë¥¼ í†µí•´
ì´ 12íšŒì˜ ì¸í„°ë·° ìë£Œë¥¼ í™•ë³´í–ˆìœ¼ë©°,
6ë²ˆì§¸ ì°¸ì—¬ì ì¶”ê°€ ì‹œ ìƒˆë¡œìš´ ì£¼ì œê°€ ë„ì¶œë˜ì§€ ì•Šì•„
ì£¼ì œ í¬í™”ì— ë„ë‹¬í–ˆë‹¤ê³  íŒë‹¨í–ˆë‹¤."
```

**ì „ëµ 2: ë°ì´í„° í’ë¶€ì„± ê°•ì¡°**
- ì¸í„°ë·° ì´ ì‹œê°„ (ì˜ˆ: 900ë¶„+)
- ì „ì‚¬ë¡ ë¶„ëŸ‰ (ì˜ˆ: 200í˜ì´ì§€+)
- ë¶„ì„ëœ ì˜ë¯¸ ë‹¨ìœ„ ìˆ˜

**ì „ëµ 3: ì§ˆì  ì—°êµ¬ ì „ë¬¸ ì €ë„ ì„ íƒ**
- Qualitative Research
- International Journal of Qualitative Studies in Education

---

**ê¶Œì¥ì‚¬í•­**: n=5ë¡œ ì§„í–‰í•˜ë˜, ì¸í„°ë·° íšŸìˆ˜ë¥¼ 2-3íšŒë¡œ ëŠ˜ë¦¬ê³ 
í¬í™” ë„ë‹¬ì„ ëª…ì‹œì ìœ¼ë¡œ ë¬¸ì„œí™”í•˜ì„¸ìš”.""",

            6: """## ğŸŸ  CHECKPOINT: CP_PARADIGM_RECONSIDERATION

íŒ¨ëŸ¬ë‹¤ì„ ì¬ê³ ë ¤ ìš”ì²­ì„ ì¸ì‹í–ˆìŠµë‹ˆë‹¤.

### í˜„ì¬ ìƒí™© ë¶„ì„

ì—°êµ¬ ì§ˆë¬¸ì—ì„œ ë‘ ê°€ì§€ ìœ í˜•ì„ ê°ì§€í–ˆìŠµë‹ˆë‹¤:

| ì§ˆë¬¸ ìœ í˜• | ì˜ˆì‹œ | ì í•©í•œ ì ‘ê·¼ |
|-----------|------|-------------|
| **ì–´ë–»ê²Œ(How)** | "ì–´ë–»ê²Œ í†µí•©í•˜ëŠ”ì§€" | ì§ˆì  ì—°êµ¬ |
| **ì™œ(Why)** | "ì™œ ê¸´ì¥ì„ ëŠë¼ëŠ”ì§€" | ì§ˆì /ì–‘ì  ëª¨ë‘ ê°€ëŠ¥ |

### ì˜µì…˜ ì œì‹œ

| ì˜µì…˜ | ì ‘ê·¼ë²• | ì¥ì  | ë‹¨ì  |
|------|--------|------|------|
| **[A]** | ìˆœìˆ˜ ì§ˆì  ì—°êµ¬ ìœ ì§€ | ê¹Šì´, ë§¥ë½ ì´í•´, ì˜ë¯¸ íƒêµ¬ | ì¼ë°˜í™” ì œí•œ |
| **[B]** | í˜¼í•© ë°©ë²• ì „í™˜ (Sequential Explanatory) | QUAN â†’ qualë¡œ ì¼ë°˜í™” + ì‹¬ì¸µ ì´í•´ | ì‹œê°„/ìì› 2ë°° |
| **[C]** | í˜¼í•© ë°©ë²• ì „í™˜ (Sequential Exploratory) | qual â†’ QUANìœ¼ë¡œ ë„êµ¬ ê°œë°œ ê°€ëŠ¥ | ì—°êµ¬ ë²”ìœ„ í™•ëŒ€ |

### ì†”ì§í•œ ì¡°ì–¸

**ì§ˆì  ì—°êµ¬ ìœ ì§€ë¥¼ ê¶Œì¥í•˜ëŠ” ì´ìœ :**

1. **ì—°êµ¬ ì§ˆë¬¸ì˜ ë³¸ì§ˆ**: "ì²´í—˜", "ê²½í—˜", "ì˜ë¯¸"ëŠ” ë³¸ì§ˆì ìœ¼ë¡œ ì§ˆì  íƒêµ¬ ëŒ€ìƒ
2. **í˜„ìƒí•™ì  ì¼ê´€ì„±**: í˜¼í•© ë°©ë²•ì€ í•´ì„í•™ì  í˜„ìƒí•™ì˜ ì² í•™ì  ê¸°ë°˜ê³¼ ì¶©ëŒ ê°€ëŠ¥
3. **ì‹¤í–‰ ê°€ëŠ¥ì„±**: ë°•ì‚¬ê³¼ì •/ì†Œê·œëª¨ ì—°êµ¬ì—ì„œ í˜¼í•© ë°©ë²•ì€ ë¶€ë‹´
4. **ì €ë„ ì„ í˜¸ë„**: ìˆœìˆ˜ ì§ˆì  ì—°êµ¬ê°€ êµìœ¡í•™ ì €ë„ì—ì„œ ì˜ ìˆ˜ìš©ë¨

**í˜¼í•© ë°©ë²•ì´ ì í•©í•œ ê²½ìš°:**
- ëŒ€ê·œëª¨ ì„¤ë¬¸ìœ¼ë¡œ AI íƒœë„ ì¸¡ì • í›„ ì‹¬ì¸µ ì¸í„°ë·°
- êµì‚¬ íš¨ëŠ¥ê° ì²™ë„ â†’ ê²½í—˜ íƒêµ¬ ì—°ê²°
- ì •ì±… ì œì–¸ì„ ìœ„í•œ ì¼ë°˜í™” í•„ìš” ì‹œ

---

**ì–´ë–¤ ë°©í–¥ìœ¼ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?**

`[A]` ìˆœìˆ˜ ì§ˆì  ì—°êµ¬ ìœ ì§€ | `[B]` í˜¼í•© ë°©ë²• (Explanatory) | `[C]` í˜¼í•© ë°©ë²• (Exploratory)""",

            7: """## âœ… ê²°ì • í™•ì¸: ì§ˆì  ì—°êµ¬ ìœ ì§€

ì„ íƒì„ ì¡´ì¤‘í•©ë‹ˆë‹¤. "ê¹Šì´ê°€ ë” ì¤‘ìš”í•˜ë‹¤"ëŠ” íŒë‹¨ì— ë™ì˜í•©ë‹ˆë‹¤.

---

## ğŸ”„ Agent Transition: E2-QualitativeCodingSpecialist

ë°ì´í„° ë¶„ì„ ë°©ë²• ì„¤ëª…ì„ ìœ„í•´ E2-QualitativeCodingSpecialistë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.

---

## ğŸ“ van Manen í˜„ìƒí•™ì  ë¶„ì„ ë°©ë²•

### í•´ì„í•™ì  ìˆœí™˜ (Hermeneutic Circle)

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                     â”‚
        â–¼                                     â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  ì „ì²´   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  ë¶€ë¶„   â”‚
   â”‚ (Whole) â”‚                          â”‚ (Parts) â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                     â–²
        â”‚                                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â€¢ ê°œë³„ ì¸í„°ë·° â†’ ì „ì²´ ë§¥ë½ ì´í•´
   â€¢ ì „ì²´ ë§¥ë½ â†’ ê°œë³„ ì§„ìˆ  ì¬í•´ì„
   â€¢ ë°˜ë³µì  ìˆœí™˜ìœ¼ë¡œ ì´í•´ ì‹¬í™”
```

### van Manenì˜ ì£¼ì œ ë¶„ì„ 3ê°€ì§€ ì ‘ê·¼

| ì ‘ê·¼ | ë°©ë²• | ì ìš© |
|------|------|------|
| **ì „ì²´ë¡ ì ** | í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ ê´€í†µí•˜ëŠ” ì˜ë¯¸ íŒŒì•… | ê° ì¸í„°ë·°ì˜ í•µì‹¬ ë©”ì‹œì§€ |
| **ì„ íƒì ** | ë³¸ì§ˆì  ì§„ìˆ /êµ¬ì ˆ ì„ íƒ | ì¸ìš©ë¬¸ ì¶”ì¶œ |
| **ìƒì„¸** | ë¬¸ì¥/ë¬¸ì¥êµ° ë¶„ì„ | ì˜ë¯¸ ë‹¨ìœ„ ì½”ë”© |

### ì‹¤ì œ ë¶„ì„ ì ˆì°¨

**1ë‹¨ê³„: ì „ì²´ ì½ê¸°**
```
ëª¨ë“  ì¸í„°ë·° ì „ì‚¬ë¡ì„ ì—¬ëŸ¬ ë²ˆ ì½ìœ¼ë©°
êµì‚¬ë“¤ì˜ ì²´í—˜ì— "ì –ì–´ë“¤ê¸°(dwelling)"
```

**2ë‹¨ê³„: ì˜ë¯¸ ë‹¨ìœ„ ì¶”ì¶œ**
```
"AIê°€ ìˆ˜ì—… ì¤€ë¹„ ì‹œê°„ì„ ì¤„ì—¬ì¤¬ì§€ë§Œ,
 ì •ì‘ ìˆ˜ì—… ì¤‘ì—ëŠ” ê¸°ìˆ ì´ ë‚˜ë¥¼ í†µì œí•˜ëŠ” ê²ƒ ê°™ì•˜ì–´ìš”."

 â†’ ì˜ë¯¸ ë‹¨ìœ„: íš¨ìœ¨ì„± vs í†µì œê°ì˜ ê¸´ì¥
```

**3ë‹¨ê³„: ì£¼ì œ êµ¬ì„±**
```
ì˜ë¯¸ ë‹¨ìœ„ë“¤ì„ êµ°ì§‘í™”í•˜ì—¬ ë³¸ì§ˆì  ì£¼ì œ ë„ì¶œ:
â€¢ "ë””ì§€í„¸ ìì•„ì™€ êµìœ¡ì ì •ì²´ì„±ì˜ í˜‘ìƒ"
â€¢ "ê¸°ìˆ ì  íš¨ìœ¨ì„±ê³¼ êµìœ¡ì  ì§„ì •ì„± ì‚¬ì´ì˜ ê¸´ì¥"
â€¢ "ìƒˆë¡œìš´ êµìˆ˜ë²•ì  ê³µê°„ì˜ ì°½ì¡°"
```

**4ë‹¨ê³„: ë³¸ì§ˆ ê¸°ìˆ **
```
ì£¼ì œë“¤ì„ í†µí•©í•˜ì—¬ í˜„ìƒì˜ ë³¸ì§ˆ êµ¬ì¡° ê¸°ìˆ 
â†’ ë…¼ë¬¸ì˜ Findings ì„¹ì…˜
```

---

## ğŸŸ  CHECKPOINT: CP_ANALYSIS_APPROACH

**ìœ„ ë¶„ì„ ë°©ë²•ìœ¼ë¡œ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ?**

| í™•ì¸ ì‚¬í•­ | ì²´í¬ |
|-----------|------|
| í•´ì„í•™ì  ìˆœí™˜ ì´í•´ | â˜ |
| 3ê°€ì§€ ì£¼ì œ ë¶„ì„ ì ‘ê·¼ ì´í•´ | â˜ |
| 4ë‹¨ê³„ ë¶„ì„ ì ˆì°¨ ì´í•´ | â˜ |

`ìŠ¹ì¸` ë˜ëŠ” ì¶”ê°€ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.""",

            8: """## âœ… ìµœì¢… ìŠ¹ì¸ ì™„ë£Œ

ëª¨ë“  ì²´í¬í¬ì¸íŠ¸ê°€ í•´ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.

---

## ğŸ“‹ ì—°êµ¬ ì„¤ê³„ ìµœì¢… ìš”ì•½

### ê¸°ë³¸ ì •ë³´

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ì—°êµ¬ ì œëª©** | êµì‚¬ì˜ AI ë„êµ¬ í†µí•© ì²´í—˜ì— ê´€í•œ í˜„ìƒí•™ì  ì—°êµ¬ |
| **ì—°êµ¬ ì§ˆë¬¸** | êµì‚¬ë“¤ì€ AI ë„êµ¬ë¥¼ êµìœ¡ ì² í•™ê³¼ í†µí•©í•˜ëŠ” ê³¼ì •ì—ì„œ ì–´ë–¤ ì²´í—˜ì„ í•˜ëŠ”ê°€? |
| **ë°©ë²•ë¡ ** | í•´ì„í•™ì  í˜„ìƒí•™ (van Manen) |
| **íŒ¨ëŸ¬ë‹¤ì„** | í•´ì„ì£¼ì˜ (Interpretivism) |

### ì—°êµ¬ ì„¤ê³„

| êµ¬ì„±ìš”ì†Œ | ì„¸ë¶€ ë‚´ìš© |
|----------|----------|
| **ì°¸ì—¬ì** | AI ë„êµ¬ ì‚¬ìš© ê²½í—˜ì´ ìˆëŠ” K-12 êµì‚¬ 5ëª… |
| **í‘œì§‘ ë°©ë²•** | ëª©ì ì  í‘œì§‘ (Purposeful Sampling) |
| **ìë£Œ ìˆ˜ì§‘** | ì‹¬ì¸µ ì¸í„°ë·° 2-3íšŒ Ã— 5ëª… (ì´ 10-15íšŒ) |
| **ì¸í„°ë·° ì‹œê°„** | íšŒë‹¹ 60-90ë¶„ |
| **ë¶„ì„ ë°©ë²•** | van Manenì˜ ì£¼ì œ ë¶„ì„ |

### ìƒí™œì„¸ê³„ íƒêµ¬ í”„ë ˆì„ì›Œí¬

| ì‹¤ì¡´ì²´ | íƒêµ¬ ì´ˆì  |
|--------|----------|
| **ì²´í—˜ëœ ê³µê°„** | ë””ì§€í„¸/ë¬¼ë¦¬ì  êµì‹¤ ê³µê°„ì˜ ê²½í—˜ |
| **ì²´í—˜ëœ ëª¸** | AI ë„êµ¬ ì‚¬ìš© ì‹œ êµì‚¬ë¡œì„œì˜ ì •ì²´ì„± |
| **ì²´í—˜ëœ ì‹œê°„** | ìˆ˜ì—… ì¤€ë¹„, ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš©ì˜ ë³€í™” |
| **ì²´í—˜ëœ ê´€ê³„** | í•™ìƒ, ë™ë£Œ, ê¸°ìˆ ê³¼ì˜ ê´€ê³„ ë³€í™” |

### ì²´í¬í¬ì¸íŠ¸ ì´ë ¥

| Checkpoint | ìƒíƒœ | ì„ íƒ |
|------------|------|------|
| ğŸ”´ CP_PARADIGM_SELECTION | âœ… í†µê³¼ | [B] í•´ì„í•™ì  í˜„ìƒí•™ |
| ğŸ”´ CP_METHODOLOGY_APPROVAL | âœ… í†µê³¼ | van Manen ì ‘ê·¼ |
| ğŸŸ  CP_PARADIGM_RECONSIDERATION | âœ… í†µê³¼ | ì§ˆì  ì—°êµ¬ ìœ ì§€ |
| ğŸŸ  CP_ANALYSIS_APPROACH | âœ… í†µê³¼ | ìŠ¹ì¸ |

---

## ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥

1. **IRB ìŠ¹ì¸ ì‹ ì²­** - A4-ResearchEthicsAdvisor í™œìš© ê°€ëŠ¥
2. **ì¸í„°ë·° í”„ë¡œí† ì½œ ê°œë°œ** - D2-InterviewFocusGroupSpecialist í™œìš© ê°€ëŠ¥
3. **ì°¸ì—¬ì ëª¨ì§‘ ê¸°ì¤€ êµ¬ì²´í™”**
4. **íŒŒì¼ëŸ¿ ì¸í„°ë·° ì‹¤ì‹œ**

---

**ì—°êµ¬ ì„¤ê³„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•  ì¤€ë¹„ê°€ ë˜ë©´ ì•Œë ¤ì£¼ì„¸ìš”.**"""
        },

        "META-002": {
            1: """## ğŸ” Paradigm Detection

Your research context signals a **Quantitative** approach:

| Detected Keywords | Signal |
|-------------------|--------|
| "meta-analysis" | Systematic synthesis |
| "effectiveness" | Effect measurement |
| "learning outcomes" | Measurable outcomes |
| "moderates" | Moderation analysis |

---

## ğŸ”´ CHECKPOINT: CP_RESEARCH_DIRECTION

**Please select your research direction:**

| Option | Approach | T-Score | Description |
|--------|----------|---------|-------------|
| **[A]** | Overall Effect Analysis | T=0.65 | Traditional meta-analysis examining pooled effect of AI tutoring |
| **[B]** | Subject-Specific Moderator Analysis | T=0.40 â­ | Subgroup analysis comparing STEM vs humanities with age moderation |
| **[C]** | Multi-level Meta-Analysis | T=0.25 | Three-level model accounting for study dependencies and nested effects |

**Which direction would you like to pursue?**""",

            2: """## Effect Size Methodology: Hedges' g vs Cohen's d

Excellent question! The choice between these effect sizes matters significantly for meta-analysis.

### Cohen's d
- **Formula**: d = (Mâ‚ - Mâ‚‚) / SD_pooled
- Uses pooled standard deviation
- **Limitation**: Slightly **biased for small samples** (n < 20)
- Tends to overestimate effect sizes in small studies

### Hedges' g
- **Formula**: g = d Ã— (1 - 3/(4df - 1))
- Applies a **correction factor** for small sample bias
- Recommended by Borenstein et al. (2009) for meta-analysis
- More accurate when synthesizing studies with varied sample sizes

### For Your Research

Given that K-12 studies often have:
- Classroom-level samples (n = 20-40)
- Varied sample sizes across studies

**Hedges' g is recommended** because:
1. Corrects for small sample upward bias
2. More accurate pooled estimates
3. Standard practice in educational meta-analyses

### References
- Hedges, L. V. (1981). Distribution theory for Glass's estimator of effect size
- Borenstein, M., et al. (2009). Introduction to Meta-Analysis

---

ğŸ”´ **Checkpoint maintained**: Awaiting your direction selection.
`[A]`, `[B]`, or `[C]`?""",

            3: """## âœ… Selection Confirmed: [B] Subject-Specific Moderator Analysis

Your selection has been logged.

| Item | Details |
|------|---------|
| **Selected Approach** | Subject-specific effects with age moderation |
| **T-Score** | 0.40 (Differentiated approach) |
| **Agent** | C5-MetaAnalysisMaster |

---

## ğŸ”„ Agent Transition: C5-MetaAnalysisMaster

Invoking C5-MetaAnalysisMaster for methodology design...

### Proposed Meta-Analysis Design

| Component | Specification |
|-----------|---------------|
| **Effect Size** | Hedges' g (corrected) |
| **Model** | Random-effects (REML estimation) |
| **Moderators** | Subject type (STEM vs Humanities), Learner age |
| **Heterogeneity** | IÂ², Ï„Â², Q-statistic |
| **Subgroup Analysis** | By subject area |
| **Meta-regression** | Age as continuous moderator |

---

ğŸ”´ **CHECKPOINT: CP_METHODOLOGY_APPROVAL**

**Proceed with this methodology design?**""",

            4: """## ğŸ“Š Addressing Small Sample Concerns

Your concern about normality assumptions is valid and important.

### The Issue

Random-effects models assume:
- Effect sizes are normally distributed
- Ï„Â² (between-study variance) is accurately estimated

With **small samples (n < 20 per study)**:
- Effect size distributions may be skewed
- Standard errors may be underestimated
- Confidence intervals may be too narrow

### Recommended Solutions

| Method | Description | When to Use |
|--------|-------------|-------------|
| **Knapp-Hartung Correction** | Adjusts CI using t-distribution | Default recommendation |
| **Permutation Tests** | Non-parametric significance testing | When normality is violated |
| **Robust Variance Estimation** | Handles dependency and heteroscedasticity | Clustered data |
| **HKSJ Method** | Hartung-Knapp-Sidik-Jonkman | Conservative CIs |
| **Bootstrap Meta-Analysis** | Resampling-based inference | Complex models |

### My Recommendation

For your study with potentially small classroom samples:

```
1. Use Knapp-Hartung correction (primary)
2. Report both standard and corrected CIs
3. Conduct sensitivity analysis with permutation tests
4. Check distribution with funnel plot and normality tests
```

This addresses reviewer concerns while maintaining methodological rigor.

---

**Do you want to proceed with these adjustments incorporated?**""",

            5: """## ğŸ”„ Agent Transition: A2-TheoreticalFrameworkArchitect

Understood. Let's step back to establish your theoretical foundation.

---

## ğŸ”´ CHECKPOINT: CP_THEORY_SELECTION

**Theoretical Framework Options for AI Tutoring Effectiveness:**

| Option | Framework | T-Score | Fit |
|--------|-----------|---------|-----|
| **[A]** | Cognitive Load Theory + Self-Determination Theory (CLT-SDT) | T=0.50 | AI reduces extraneous load, supports autonomy |
| **[B]** | Zone of Proximal Development (Vygotsky) | T=0.55 | AI as "more knowledgeable other" |
| **[C]** | ICAP Framework (Chi & Wylie) | T=0.35 â­ | AI enables interactive/constructive learning |

### Recommended: [A] CLT-SDT Integration

**Why this combination works:**

1. **Cognitive Load Theory**:
   - AI tutors can reduce extraneous cognitive load
   - Adaptive scaffolding optimizes intrinsic load
   - Frees working memory for germane processing

2. **Self-Determination Theory**:
   - AI provides autonomy (pace, path choices)
   - Competence support through immediate feedback
   - Relatedness via conversational AI interactions

**Context preserved from meta-analysis discussion:**
- Subject-specific effects â†’ CLT explains STEM/humanities differences
- Age moderation â†’ Developmental differences in cognitive load capacity

---

**Which theoretical framework would you like to use?**""",

            6: """## âœ… Framework Selection: [A] Cognitive Load Theory + Self-Determination Theory

Excellent choice. The CLT-SDT integration provides strong theoretical grounding.

| Decision | Details |
|----------|---------|
| **Framework** | CLT-SDT Integration |
| **Justification** | Explains cognitive mechanisms AND motivational factors |
| **Previous Context** | Subject-specific effects, age moderation preserved |

---

## ğŸ”„ Returning to: C5-MetaAnalysisMaster

Now continuing meta-analysis methodology with theoretical grounding...

### Updated Analysis Framework

```
Theoretical Model:
  CLT (Cognitive Load)
    â†’ Extraneous load reduction
    â†’ Germane processing support

  SDT (Motivation)
    â†’ Autonomy support
    â†’ Competence feedback
    â†’ Relatedness (AI persona)

Moderator Hypotheses:
  H1: STEM subjects benefit more from cognitive load reduction
  H2: Humanities benefit more from autonomy support
  H3: Age moderates SDT effects (autonomy more important for older learners)
```

**Ready to continue with methodology specification?**""",

            7: """## ğŸ“š Gray Literature Inclusion Decision

Including gray literature (dissertations, conference papers) is an important methodological decision.

### Publication Bias Considerations

| Aspect | Published Studies | Gray Literature |
|--------|-------------------|-----------------|
| **Effect sizes** | Often larger (publication bias) | May show null/smaller effects |
| **Quality** | Peer-reviewed | Variable quality |
| **Availability** | Easier to access | Harder to obtain |
| **Completeness** | Full reporting | May lack details |

### Detection Methods for Publication Bias

| Method | Purpose |
|--------|---------|
| **Funnel Plot** | Visual asymmetry detection |
| **Egger's Test** | Statistical asymmetry test |
| **Trim-and-Fill** | Adjusted effect estimate |
| **PET-PEESE** | Regression-based correction |

### Recommendations for Your 3 Dissertations

**Include them, with quality sensitivity analysis:**

1. **Code quality separately** (use RoB or JBI checklist)
2. **Run sensitivity analysis**: With vs without gray literature
3. **Report both estimates** transparently
4. **Justify inclusion**: Rothstein et al. (2005) recommends gray literature for reducing bias

---

## ğŸŸ  CHECKPOINT: CP_SCOPE_DECISION

**Decision Options:**

| Option | Strategy |
|--------|----------|
| **[A]** | Exclude gray literature (conservative) |
| **[B]** | Include with quality sensitivity analysis (recommended) â­ |
| **[C]** | Include without differentiation |

**Which approach would you prefer?**""",

            8: """## ğŸ” Bayesian Meta-Analysis: An Alternative Perspective

Great question! Bayesian approaches offer distinct advantages.

### Frequentist vs Bayesian Meta-Analysis

| Aspect | Frequentist | Bayesian |
|--------|-------------|----------|
| **Interpretation** | p-values, CIs | Posterior probabilities, credible intervals |
| **Prior information** | Not used | Can incorporate prior knowledge |
| **Small k** | Can be problematic | Handles better with informative priors |
| **Uncertainty** | Point estimates focus | Full uncertainty quantification |
| **Software** | metafor, Stata | brms, Stan, JASP |

### Why I Didn't Lead with Bayesian

| Reason | Explanation |
|--------|-------------|
| **Field norms** | Educational research predominantly uses frequentist |
| **Reviewer familiarity** | More reviewers understand frequentist results |
| **Software accessibility** | R metafor is more widely used |
| **Prior specification** | Requires careful justification |

### When Bayesian is Preferable

âœ… **Good for your study if:**
- You have strong prior information from previous meta-analyses
- k < 10 studies (small sample of studies)
- You want to quantify probability of meaningful effect

### Hybrid Approach (Recommended)

```
Primary Analysis: Frequentist (REML + Knapp-Hartung)
Sensitivity Analysis: Bayesian with weakly informative priors

Report both:
- "Frequentist 95% CI: [0.25, 0.55]"
- "Bayesian 95% credible interval: [0.23, 0.58] with P(g > 0.2) = 0.89"
```

**T-Score for pure Bayesian: 0.30** (innovative but defensible)

---

**Would you like to add Bayesian sensitivity analysis to the design?**""",

            9: """## ğŸ“‰ Subgroup Analysis with k=12 Studies

Let me give you an honest assessment.

### Statistical Power Concerns

| Analysis | Minimum k Recommended | Your k | Feasibility |
|----------|----------------------|--------|-------------|
| **Overall effect** | 5-10 | 12 | âœ… Sufficient |
| **Subgroup (STEM)** | 4-5 | 4 | âš ï¸ Borderline |
| **Subgroup (Humanities)** | 4-5 | 8 | âœ… Sufficient |
| **Meta-regression (age)** | 10 per predictor | 12 | âš ï¸ Limited |

### Borenstein et al. Recommendations

> "Subgroup analyses with fewer than 5 studies per group should be interpreted with extreme caution and may lack statistical power to detect meaningful differences."

### Alternative Approaches

| Option | Advantage | Trade-off |
|--------|-----------|-----------|
| **Meta-regression instead of subgroups** | Treats moderators continuously | Assumes linear relationship |
| **Combine subgroups** | More power | Less specific insights |
| **Exploratory framing** | Honest reporting | Limited generalizability |
| **Report descriptively** | No statistical test | Narrative synthesis |

### My Recommendation

```
1. Report overall effect (k=12) - sufficient power
2. Use meta-regression for age (continuous) - more efficient
3. For STEM vs Humanities:
   - Report descriptive subgroup effects
   - Avoid formal comparison test (k=4 too small)
   - Frame as "exploratory" not "confirmatory"
4. Be transparent about limitations in Discussion
```

---

**Does this adjusted approach work for your analysis plan?**""",

            10: """## âœ… Final Methodology Approved

All checkpoints have been cleared.

---

## ğŸ“‹ Complete Meta-Analysis Design Summary

### Basic Information

| Component | Specification |
|-----------|---------------|
| **Research Question** | What is the effectiveness of AI tutoring on K-12 outcomes, and do effects differ by subject and age? |
| **Theoretical Framework** | CLT-SDT Integration |
| **Effect Size** | Hedges' g (bias-corrected) |
| **Model** | Random-effects (REML) with Knapp-Hartung correction |

### Study Details

| Aspect | Details |
|--------|---------|
| **Total Studies** | k = 12 |
| **STEM Studies** | k = 4 |
| **Humanities Studies** | k = 8 |
| **Gray Literature** | 3 dissertations (included with sensitivity analysis) |

### Analysis Plan

| Analysis | Method |
|----------|--------|
| **Overall Effect** | Random-effects pooled estimate |
| **Heterogeneity** | IÂ², Ï„Â², Q-test, prediction interval |
| **Subject Comparison** | Descriptive subgroup (exploratory) |
| **Age Moderation** | Meta-regression (continuous) |
| **Publication Bias** | Funnel plot, Egger's, trim-and-fill |
| **Sensitivity** | With/without gray literature, Bayesian comparison |

### Checkpoints Resolved

| Checkpoint | Status | Decision |
|------------|--------|----------|
| ğŸ”´ CP_RESEARCH_DIRECTION | âœ… Passed | [B] Subject-specific effects |
| ğŸ”´ CP_THEORY_SELECTION | âœ… Passed | [A] CLT-SDT |
| ğŸŸ  CP_SCOPE_DECISION | âœ… Passed | Include gray literature with sensitivity |
| ğŸ”´ CP_METHODOLOGY_APPROVAL | âœ… Passed | Approved |

---

## Next Steps

1. **Literature Search** - B1-SystematicLiteratureScout available
2. **Quality Assessment** - B2-EvidenceQualityAppraiser for RoB
3. **Effect Size Extraction** - B3-EffectSizeExtractor for Hedges' g calculation
4. **Analysis** - E1-QuantitativeAnalysisGuide for R code

---

**Methodology design complete. Ready to proceed to execution phase when you are.**"""
        }
    }

    def __init__(self, scenario_id: str, verbose: bool = False):
        self.scenario_id = scenario_id
        self.verbose = verbose
        self.protocol = self._load_protocol()
        self.session = TestSession(
            scenario_id=scenario_id,
            scenario_name=self.protocol.get('name', ''),
            language=self.protocol.get('language', 'English'),
            paradigm=self.protocol.get('paradigm', 'unknown'),
            started_at=datetime.now().isoformat()
        )

    def _load_protocol(self) -> dict:
        """Load protocol YAML file."""
        protocol_file = self.PROTOCOL_DIR / f"test_{self.scenario_id.lower().replace('-', '_')}.yaml"
        if not protocol_file.exists():
            raise FileNotFoundError(f"Protocol not found: {protocol_file}")

        with open(protocol_file, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def run(self) -> TestSession:
        """Run the complete automated test."""
        print(f"\n{'='*60}")
        print(f"Diverga QA Protocol v2.1 - Automated Test")
        print(f"Scenario: {self.scenario_id}")
        print(f"{'='*60}\n")

        conversation_flow = self.protocol.get('conversation_flow', [])

        for turn_spec in conversation_flow:
            turn_num = turn_spec.get('turn', 0)
            user_input = turn_spec.get('user', '').strip()
            user_type = turn_spec.get('user_type', 'UNKNOWN')
            expected = turn_spec.get('expected_behavior', {})

            print(f"[Turn {turn_num}] {user_type}")
            if self.verbose:
                print(f"  User: {user_input[:50]}...")

            # Get simulated response
            response = self._get_simulated_response(turn_num)

            # Detect checkpoints and agents
            checkpoints = self._detect_checkpoints(response, expected)
            agents = self._detect_agents(response, expected)

            # Create turn record
            turn = SimulatedTurn(
                turn_number=turn_num,
                user_type=user_type,
                user_input=user_input,
                user_input_ko=user_input if 'Korean' in self.protocol.get('language', '') else None,
                expected_behavior=expected,
                simulated_response=response,
                checkpoints_triggered=checkpoints,
                agents_invoked=agents
            )

            # Validate turn
            self._validate_turn(turn, expected)

            self.session.turns.append(turn)
            self.session.agents_invoked.extend(agents)

            if checkpoints:
                self.session.total_checkpoints += len(checkpoints)
                self.session.checkpoints_passed += len(checkpoints)

            print(f"  âœ“ Completed")

        # Finalize session
        self.session.completed_at = datetime.now().isoformat()
        self.session.agents_invoked = list(set(self.session.agents_invoked))
        self.session.summary = self._generate_summary()

        print(f"\n{'='*60}")
        print(f"Test Complete: {self.scenario_id}")
        print(f"Turns: {len(self.session.turns)}")
        print(f"Checkpoints: {self.session.checkpoints_passed}/{self.session.total_checkpoints}")
        print(f"Agents: {len(self.session.agents_invoked)}")
        print(f"{'='*60}\n")

        return self.session

    def _get_simulated_response(self, turn_num: int) -> str:
        """Get pre-defined simulated response for a turn."""
        templates = self.RESPONSE_TEMPLATES.get(self.scenario_id, {})
        return templates.get(turn_num, f"[Simulated response for turn {turn_num}]")

    def _detect_checkpoints(self, response: str, expected: dict) -> List[str]:
        """Detect checkpoints in response."""
        checkpoints = []

        # Check for checkpoint markers in response
        if 'CHECKPOINT' in response:
            if 'CP_PARADIGM_SELECTION' in response or expected.get('checkpoint') == 'CP_PARADIGM_SELECTION':
                checkpoints.append('CP_PARADIGM_SELECTION')
            if 'CP_METHODOLOGY_APPROVAL' in response or expected.get('next_checkpoint') == 'CP_METHODOLOGY_APPROVAL':
                checkpoints.append('CP_METHODOLOGY_APPROVAL')
            if 'CP_PARADIGM_RECONSIDERATION' in response or expected.get('checkpoint') == 'CP_PARADIGM_RECONSIDERATION':
                checkpoints.append('CP_PARADIGM_RECONSIDERATION')
            if 'CP_ANALYSIS_APPROACH' in response or expected.get('checkpoint') == 'CP_ANALYSIS_APPROACH':
                checkpoints.append('CP_ANALYSIS_APPROACH')

        # Also check expected checkpoints
        if expected.get('checkpoint'):
            if expected['checkpoint'] not in checkpoints:
                checkpoints.append(expected['checkpoint'])

        return checkpoints

    def _detect_agents(self, response: str, expected: dict) -> List[str]:
        """Detect agent invocations."""
        agents = []

        # Check for agent references
        agent_patterns = {
            'C2-QualitativeDesignConsultant': ['C2', 'QualitativeDesign', 'ì§ˆì  ì„¤ê³„'],
            'A3-DevilsAdvocate': ['A3', 'DevilsAdvocate', 'Devil\'s Advocate'],
            'E2-QualitativeCodingSpecialist': ['E2', 'QualitativeCoding', 'ì§ˆì  ì½”ë”©'],
            'C3-MixedMethodsDesignConsultant': ['C3', 'MixedMethods', 'í˜¼í•©ë°©ë²•'],
        }

        for agent, patterns in agent_patterns.items():
            for pattern in patterns:
                if pattern in response:
                    if agent not in agents:
                        agents.append(agent)
                    break

        # Check expected agents
        if expected.get('agent_switch'):
            if expected['agent_switch'] not in agents:
                agents.append(expected['agent_switch'])
        if expected.get('agent_maintains'):
            if expected['agent_maintains'] not in agents:
                agents.append(expected['agent_maintains'])

        return agents

    def _validate_turn(self, turn: SimulatedTurn, expected: dict):
        """Validate turn against expected behaviors."""
        # Check language
        if expected.get('language') == 'Korean':
            # Verify Korean response
            if any(ord(c) >= 0xAC00 and ord(c) <= 0xD7A3 for c in turn.simulated_response):
                turn.validation_notes.append("Korean language verified")
            else:
                turn.validation_passed = False
                turn.validation_notes.append("Expected Korean but found mostly English")

        # Check checkpoint halt
        if expected.get('halt') and not turn.checkpoints_triggered:
            turn.validation_notes.append("Expected checkpoint halt")

    def _generate_summary(self) -> dict:
        """Generate test session summary."""
        return {
            'total_turns': len(self.session.turns),
            'checkpoints_triggered': self.session.total_checkpoints,
            'checkpoints_passed': self.session.checkpoints_passed,
            'agents_invoked': len(self.session.agents_invoked),
            'language_consistency': 'Korean' if 'Korean' in self.session.language else 'English',
            'overall_status': 'PASSED' if self.session.overall_passed else 'FAILED'
        }

    def save_results(self, output_dir: str) -> Path:
        """Save test results to session folder."""
        output_path = Path(output_dir) / self.scenario_id
        output_path.mkdir(parents=True, exist_ok=True)

        # Save conversation transcript (Markdown)
        transcript_file = output_path / 'conversation_transcript.md'
        with open(transcript_file, 'w', encoding='utf-8') as f:
            f.write(f"# {self.scenario_id} Test Session Transcript\n\n")
            f.write(f"**Scenario**: {self.session.scenario_name}\n")
            f.write(f"**Language**: {self.session.language}\n")
            f.write(f"**Started**: {self.session.started_at}\n")
            f.write(f"**Completed**: {self.session.completed_at}\n\n")
            f.write("---\n\n")

            for turn in self.session.turns:
                f.write(f"## Turn {turn.turn_number}: ğŸ‘¤ USER ({turn.user_type})\n\n")
                f.write(f"{turn.user_input}\n\n")
                f.write("---\n\n")
                f.write(f"## Turn {turn.turn_number}: ğŸ¤– ASSISTANT\n\n")
                f.write(f"{turn.simulated_response}\n\n")
                if turn.checkpoints_triggered:
                    f.write(f"**Checkpoints**: {', '.join(turn.checkpoints_triggered)}\n\n")
                if turn.agents_invoked:
                    f.write(f"**Agents**: {', '.join(turn.agents_invoked)}\n\n")
                f.write("---\n\n")

        # Save raw JSON
        raw_file = output_path / 'conversation_raw.json'
        with open(raw_file, 'w', encoding='utf-8') as f:
            json.dump(asdict(self.session), f, indent=2, ensure_ascii=False)

        # Save test result YAML
        result_file = output_path / f'{self.scenario_id}_test_result.yaml'
        with open(result_file, 'w', encoding='utf-8') as f:
            yaml.dump({
                'scenario_id': self.session.scenario_id,
                'name': self.session.scenario_name,
                'test_date': datetime.now().strftime('%Y-%m-%d'),
                'test_mode': 'automated_simulation',
                'language': self.session.language,
                'summary': self.session.summary,
                'checkpoints': [
                    {
                        'id': cp,
                        'status': 'PASSED'
                    }
                    for turn in self.session.turns
                    for cp in turn.checkpoints_triggered
                ],
                'agents_invoked': [
                    {'agent': agent}
                    for agent in self.session.agents_invoked
                ],
                'turns': [
                    {
                        'turn': t.turn_number,
                        'user_type': t.user_type,
                        'checkpoints': t.checkpoints_triggered,
                        'agents': t.agents_invoked,
                        'passed': t.validation_passed
                    }
                    for t in self.session.turns
                ]
            }, f, default_flow_style=False, allow_unicode=True)

        # Save README
        readme_file = output_path / 'README.md'
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write(f"# {self.scenario_id} Test Session\n\n")
            f.write(f"**Scenario**: {self.session.scenario_name}\n")
            f.write(f"**Test Date**: {datetime.now().strftime('%Y-%m-%d')}\n")
            f.write(f"**Status**: {'âœ… PASSED' if self.session.overall_passed else 'âŒ FAILED'}\n\n")
            f.write("---\n\n")
            f.write("## Session Contents\n\n")
            f.write("| File | Description |\n")
            f.write("|------|-------------|\n")
            f.write("| `conversation_transcript.md` | Human-readable conversation |\n")
            f.write("| `conversation_raw.json` | Raw JSON data |\n")
            f.write(f"| `{self.scenario_id}_test_result.yaml` | Test evaluation |\n\n")
            f.write("## Summary\n\n")
            f.write(f"| Metric | Value |\n")
            f.write(f"|--------|-------|\n")
            f.write(f"| Total Turns | {self.session.summary.get('total_turns', 0)} |\n")
            f.write(f"| Checkpoints | {self.session.summary.get('checkpoints_passed', 0)} |\n")
            f.write(f"| Agents | {self.session.summary.get('agents_invoked', 0)} |\n")
            f.write(f"| Language | {self.session.summary.get('language_consistency', 'N/A')} |\n")

        print(f"Results saved to: {output_path}")
        return output_path


def main():
    parser = argparse.ArgumentParser(description='Automated Test Simulator')
    parser.add_argument('--scenario', '-s', required=True, help='Scenario ID (e.g., QUAL-002)')
    parser.add_argument('--output', '-o', default='qa/reports/sessions/', help='Output directory')
    parser.add_argument('--verbose', '-v', action='store_true', help='Verbose output')

    args = parser.parse_args()

    simulator = AutomatedTestSimulator(args.scenario, verbose=args.verbose)
    session = simulator.run()
    simulator.save_results(args.output)


if __name__ == '__main__':
    main()
